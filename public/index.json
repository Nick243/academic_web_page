[{"authors":["admin"],"categories":null,"content":"Nicholas Ollberding is a quantitative epidemiologist with applied research interests investigating the role of diet in the etiology and progression of chronic disease and the role of the developing infant intestinal microbiome on growth and early development. Areas of methodical research interest include the development and application of analytical methods for microbial metagenomic next-generation sequence data and dietary assessment and analysis methodology. He also collaborates broadly as a quantitative methodologist and statistician in the area of health sciences research and leads the Biostatistics Core of the Heart Institute Research Core at Cincinnati Children’s Hospital Medical Center.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Nicholas Ollberding is a quantitative epidemiologist with applied research interests investigating the role of diet in the etiology and progression of chronic disease and the role of the developing infant intestinal microbiome on growth and early development. Areas of methodical research interest include the development and application of analytical methods for microbial metagenomic next-generation sequence data and dietary assessment and analysis methodology. He also collaborates broadly as a quantitative methodologist and statistician in the area of health sciences research and leads the Biostatistics Core of the Heart Institute Research Core at Cincinnati Children’s Hospital Medical Center.","tags":null,"title":"Nicholas Ollberding","type":"authors"},{"authors":null,"categories":null,"content":" Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":" Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":["Microbiome"],"content":"\r\r\nThis post is from a tutorial demonstrating the processing of amplicon short read data in R taught as part of the Introduction to Metagenomics Summer Workshop. It provides a quick introduction some of the functionality provided by phyloseq and follows some of Paul McMurdie’s excellent tutorials. This tutorial picks up where Ben Callahan’s DADA2 tutorial leaves off and highlights some of the main accessor and processor functions of the package. I thought it might be useful to a broader audience so decided to post it.\n\nThe goal of this interactive session is to introduce you to some of the basic functionality of the phyloseq package that can help you to explore and better understand your metagenomic data. We will be working with the phyloseq object that was created during the DADA2 tutorial. If you recall, these were murine stool samples collected from a single mouse over time. The phyloseq object contains: an ASV table, sample metadata, taxonomic classifications, and the reference sequences. We did not generate a phylogenetic tree from these sequences, but if we had, it could be included as well.\nThe session will quickly cover some of the basic accessor, analysis and graphical functions available to you when using the phyloseq package in R.\nTo learn more, Paul McMurdie has an excellent set of tutorials that I encourage you to explore.\n\rhttps://joey711.github.io/phyloseq/preprocess.html\rhttps://joey711.github.io/phyloseq/index.html\r\r\n\rLoading required packages and phyloseq object\rlibrary(dada2); packageVersion(\u0026quot;dada2\u0026quot;) \r## Loading required package: Rcpp\r## [1] \u0026#39;1.12.1\u0026#39;\rlibrary(phyloseq); packageVersion(\u0026quot;phyloseq\u0026quot;) \r## [1] \u0026#39;1.28.0\u0026#39;\rlibrary(ggplot2); packageVersion(\u0026quot;ggplot2\u0026quot;) \r## [1] \u0026#39;3.2.0\u0026#39;\r\nIf the phyloseq (ps) object is not already loaded into your environment…let’s go ahead and do that now. You will need to change the path so that it maps to the ps object on your computer. No path is needed if you are working in an RStudio project folder (or if you cloned the folder from GitHub).\nps \u0026lt;- readRDS(\u0026quot;C:/Users/olljt2/Desktop/academic_web_page/static/data/ps.rds\u0026quot;)\r\n\rAccessing the sample information and sample metadata\rps\r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 232 taxa and 19 samples ]\r## sample_data() Sample Data: [ 19 samples by 4 sample variables ]\r## tax_table() Taxonomy Table: [ 232 taxa by 7 taxonomic ranks ]\r## refseq() DNAStringSet: [ 232 reference sequences ]\r\rHere we can see that we have a phyloseq object that consists of:\r\rAn OTU table with 232 taxa and 19 samples\rA sample metadata file consisting of 4 variables\rA taxonomy table with 7 ranks\rReference sequences on all 232 taxa\r\r\r\nThis highlights one of the key advantages of working with phyloseq objects in R. Each of these data structures is contained in a single object. This makes it easy to keep all of your data together and to share it with colleagues or include it as a supplemental file to a publication.\nNext we will see how each of the components can be accessed. We will run through several commands below and then discuss the output.\nnsamples(ps)\r## [1] 19\rsample_names(ps)\r## [1] \u0026quot;F3D0\u0026quot; \u0026quot;F3D1\u0026quot; \u0026quot;F3D141\u0026quot; \u0026quot;F3D142\u0026quot; \u0026quot;F3D143\u0026quot; \u0026quot;F3D144\u0026quot; \u0026quot;F3D145\u0026quot;\r## [8] \u0026quot;F3D146\u0026quot; \u0026quot;F3D147\u0026quot; \u0026quot;F3D148\u0026quot; \u0026quot;F3D149\u0026quot; \u0026quot;F3D150\u0026quot; \u0026quot;F3D2\u0026quot; \u0026quot;F3D3\u0026quot; ## [15] \u0026quot;F3D5\u0026quot; \u0026quot;F3D6\u0026quot; \u0026quot;F3D7\u0026quot; \u0026quot;F3D8\u0026quot; \u0026quot;F3D9\u0026quot;\rsample_variables(ps)\r## [1] \u0026quot;Subject\u0026quot; \u0026quot;Gender\u0026quot; \u0026quot;Day\u0026quot; \u0026quot;When\u0026quot;\rhead(sample_data(ps))\r## Subject Gender Day When\r## F3D0 3 F 0 Early\r## F3D1 3 F 1 Early\r## F3D141 3 F 141 Late\r## F3D142 3 F 142 Late\r## F3D143 3 F 143 Late\r## F3D144 3 F 144 Late\rsample_data(ps)$When\r## [1] \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot; \u0026quot;Late\u0026quot; \u0026quot;Late\u0026quot; \u0026quot;Late\u0026quot; \u0026quot;Late\u0026quot; \u0026quot;Late\u0026quot; \u0026quot;Late\u0026quot; ## [9] \u0026quot;Late\u0026quot; \u0026quot;Late\u0026quot; \u0026quot;Late\u0026quot; \u0026quot;Late\u0026quot; \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot;\r## [17] \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot;\rtable(sample_data(ps)$When)\r## ## Early Late ## 9 10\rmedian(sample_data(ps)$Day)\r## [1] 141\rmetadata \u0026lt;- data.frame(sample_data(ps))\rhead(metadata)\r## Subject Gender Day When\r## F3D0 3 F 0 Early\r## F3D1 3 F 1 Early\r## F3D141 3 F 141 Late\r## F3D142 3 F 142 Late\r## F3D143 3 F 143 Late\r## F3D144 3 F 144 Late\rHere we can see that we have 19 samples and they are assigned the sample names we gave them during the DADA2 tutorial.\rWe also have 4 variables (Subject, Gender, Day, and When) and that information can be easily accessed and computations or descriptive statistics performed.\rSpecific components of the ps object can be extracted and converted to a data.frame for additional analyses.\n\n\rExamining the number of reads for each sample\rPhyloseq makes it easy to calculate the total number of reads for each sample, sort them to identify potentially problematic samples, and plot their distribution.\nsample_sums(ps)\r## F3D0 F3D1 F3D141 F3D142 F3D143 F3D144 F3D145 F3D146 F3D147 F3D148 ## 6528 5017 4863 2521 2518 3488 5820 3879 13006 9935 ## F3D149 F3D150 F3D2 F3D3 F3D5 F3D6 F3D7 F3D8 F3D9 ## 10653 4240 16835 5491 3716 6679 4217 4547 6015\rsort(sample_sums(ps))\r## F3D143 F3D142 F3D144 F3D5 F3D146 F3D7 F3D150 F3D8 F3D141 F3D1 ## 2518 2521 3488 3716 3879 4217 4240 4547 4863 5017 ## F3D3 F3D145 F3D9 F3D0 F3D6 F3D148 F3D149 F3D147 F3D2 ## 5491 5820 6015 6528 6679 9935 10653 13006 16835\rhist(sample_sums(ps), main=\u0026quot;Histogram: Read Counts\u0026quot;, xlab=\u0026quot;Total Reads\u0026quot;, border=\u0026quot;blue\u0026quot;, col=\u0026quot;green\u0026quot;, las=1, breaks=12)\rmetadata$total_reads \u0026lt;- sample_sums(ps)\rHere we see that the number of reads per sample ranges from 2,518 to 16,835 and most samples have less than 10k reads. Try to calculate the mean and median number of reads on your own.\nThe last line of code above can be used to add a new column containing the total read count to the metadata data.frame. Similarly, sample_data(ps)$total_reads \u0026lt;- sample_sums(ps) would add this information to the phyloseq object itself (as a new sample_data variable).\n\n\rExamining the OTU table\rntaxa(ps)\r## [1] 232\rhead(taxa_names(ps))\r## [1] \u0026quot;ASV1\u0026quot; \u0026quot;ASV2\u0026quot; \u0026quot;ASV3\u0026quot; \u0026quot;ASV4\u0026quot; \u0026quot;ASV5\u0026quot; \u0026quot;ASV6\u0026quot;\rhead(taxa_sums(ps))\r## ASV1 ASV2 ASV3 ASV4 ASV5 ASV6 ## 14148 9898 8862 7935 5880 5469\r(asv_tab \u0026lt;- data.frame(otu_table(ps)[1:5, 1:5]))\r## ASV1 ASV2 ASV3 ASV4 ASV5\r## F3D0 579 345 449 430 154\r## F3D1 405 353 231 69 140\r## F3D141 444 362 345 502 189\r## F3D142 289 304 158 164 180\r## F3D143 228 176 204 231 130\r\rPhyloseq allows you to easily:\r\rObtain a count of the number of taxa\rAccess their names (e.g. ASV1, ASV2, …)\rGet a count of each ASV summed over all samples\rExtract the OTU table as a data.frame\r\r\r\n\rExamining the taxonomy\rrank_names(ps)\r## [1] \u0026quot;Kingdom\u0026quot; \u0026quot;Phylum\u0026quot; \u0026quot;Class\u0026quot; \u0026quot;Order\u0026quot; \u0026quot;Family\u0026quot; \u0026quot;Genus\u0026quot; \u0026quot;Species\u0026quot;\rhead(tax_table(ps))\r## Taxonomy Table: [6 taxa by 7 taxonomic ranks]:\r## Kingdom Phylum Class Order ## ASV1 \u0026quot;Bacteria\u0026quot; \u0026quot;Bacteroidetes\u0026quot; \u0026quot;Bacteroidia\u0026quot; \u0026quot;Bacteroidales\u0026quot;\r## ASV2 \u0026quot;Bacteria\u0026quot; \u0026quot;Bacteroidetes\u0026quot; \u0026quot;Bacteroidia\u0026quot; \u0026quot;Bacteroidales\u0026quot;\r## ASV3 \u0026quot;Bacteria\u0026quot; \u0026quot;Bacteroidetes\u0026quot; \u0026quot;Bacteroidia\u0026quot; \u0026quot;Bacteroidales\u0026quot;\r## ASV4 \u0026quot;Bacteria\u0026quot; \u0026quot;Bacteroidetes\u0026quot; \u0026quot;Bacteroidia\u0026quot; \u0026quot;Bacteroidales\u0026quot;\r## ASV5 \u0026quot;Bacteria\u0026quot; \u0026quot;Bacteroidetes\u0026quot; \u0026quot;Bacteroidia\u0026quot; \u0026quot;Bacteroidales\u0026quot;\r## ASV6 \u0026quot;Bacteria\u0026quot; \u0026quot;Bacteroidetes\u0026quot; \u0026quot;Bacteroidia\u0026quot; \u0026quot;Bacteroidales\u0026quot;\r## Family Genus Species\r## ASV1 \u0026quot;Muribaculaceae\u0026quot; NA NA ## ASV2 \u0026quot;Muribaculaceae\u0026quot; NA NA ## ASV3 \u0026quot;Muribaculaceae\u0026quot; NA NA ## ASV4 \u0026quot;Muribaculaceae\u0026quot; NA NA ## ASV5 \u0026quot;Bacteroidaceae\u0026quot; \u0026quot;Bacteroides\u0026quot; NA ## ASV6 \u0026quot;Muribaculaceae\u0026quot; NA NA\rhead(tax_table(ps)[, 2])\r## Taxonomy Table: [6 taxa by 1 taxonomic ranks]:\r## Phylum ## ASV1 \u0026quot;Bacteroidetes\u0026quot;\r## ASV2 \u0026quot;Bacteroidetes\u0026quot;\r## ASV3 \u0026quot;Bacteroidetes\u0026quot;\r## ASV4 \u0026quot;Bacteroidetes\u0026quot;\r## ASV5 \u0026quot;Bacteroidetes\u0026quot;\r## ASV6 \u0026quot;Bacteroidetes\u0026quot;\rtable(tax_table(ps)[, 2])\r## ## Actinobacteria Bacteroidetes Cyanobacteria ## 6 20 3 ## Deinococcus-Thermus Epsilonbacteraeota Firmicutes ## 1 1 185 ## Patescibacteria Proteobacteria Tenericutes ## 2 7 6 ## Verrucomicrobia ## 1\r(tax_tab \u0026lt;- data.frame(tax_table(ps)[50:55, ]))\r## Kingdom Phylum Class Order\r## ASV50 Bacteria Firmicutes Clostridia Clostridiales\r## ASV51 Bacteria Firmicutes Clostridia Clostridiales\r## ASV52 Bacteria Firmicutes Clostridia Clostridiales\r## ASV53 Bacteria Epsilonbacteraeota Campylobacteria Campylobacterales\r## ASV54 Bacteria Firmicutes Clostridia Clostridiales\r## ASV55 Bacteria Firmicutes Clostridia Clostridiales\r## Family Genus Species\r## ASV50 Lachnospiraceae Acetatifactor \u0026lt;NA\u0026gt;\r## ASV51 Ruminococcaceae Ruminiclostridium_5 \u0026lt;NA\u0026gt;\r## ASV52 Lachnospiraceae Lachnospiraceae_UCG-001 \u0026lt;NA\u0026gt;\r## ASV53 Helicobacteraceae Helicobacter pylori\r## ASV54 Family_XIII \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt;\r## ASV55 Ruminococcaceae Ruminiclostridium_5 \u0026lt;NA\u0026gt;\rHere we can see that we have information on 7 taxonomic ranks from Kingdom to Species. We can easily access specific components of this object to learn more about the classifications. For example, we see that the vast majority of ASVs are classified as Firmicutes. This is in line with our expectations. Conducting such assessments may help you identify potential sequencing errors that made it through the denoising pipeline (i.e. those not assigned to a Kingdom) or to understand the proportion of sequences classified at lower levels (i.e. genus or species).\nOne could also swap out this taxonomy file for another…say using the IDTAXA function in the DECIPHER package or an alternative reference database (i.e. Silva or Greengenes). I will let you look into this on your own!\n\n\rExamining the reference sequences\rStoring the reference sequences with your phyloseq object is critical of you rename the ASV names to ASV1, ASV2, …\rThis will allow you to communicate the information on these ASVs directly (i.e. you can provide the exact sequence variant information). This information is also required to build a phylogenetic tree or BLAST the sequences against the NCBI database for example. In short, always include these in the phyloseq object.\nBelow we see that these sequences are stored as a DNAStringSet. The refseq command returns the ASV number, sequence length, and amplicon sequence for each ASV. The function dada2::nwhamming is calculating the Hamming distance of two sequences after alignment. We will discuss more about this in class. We can also pull out the component and store it as a data.frame.\nhead(refseq(ps))\r## A DNAStringSet instance of length 6\r## width seq names ## [1] 252 TACGGAGGATGCGAGCGTTAT...AAGTGTGGGTATCGAACAGG ASV1\r## [2] 252 TACGGAGGATGCGAGCGTTAT...AAGCGTGGGTATCGAACAGG ASV2\r## [3] 252 TACGGAGGATGCGAGCGTTAT...AAGCGTGGGTATCGAACAGG ASV3\r## [4] 252 TACGGAGGATGCGAGCGTTAT...AAGTGCGGGGATCGAACAGG ASV4\r## [5] 253 TACGGAGGATCCGAGCGTTAT...AAGTGTGGGTATCAAACAGG ASV5\r## [6] 252 TACGGAGGATGCGAGCGTTAT...AAGTGCGGGGATCAAACAGG ASV6\rdada2::nwhamming(as.vector(refseq(ps)[1]), as.vector(refseq(ps)[2]))\r## [1] 20\r(ref_tab \u0026lt;- data.frame(head(refseq(ps))))\r## head.refseq.ps..\r## ASV1 TACGGAGGATGCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGCAGGCGGAAGATCAAGTCAGCGGTAAAATTGAGAGGCTCAACCTCTTCGAGCCGTTGAAACTGGTTTTCTTGAGTGAGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACTCCGATTGCGAAGGCAGCATACCGGCGCTCAACTGACGCTCATGCACGAAAGTGTGGGTATCGAACAGG\r## ASV2 TACGGAGGATGCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGCAGGCGGACTCTCAAGTCAGCGGTCAAATCGCGGGGCTCAACCCCGTTCCGCCGTTGAAACTGGGAGCCTTGAGTGCGCGAGAAGTAGGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACTCCGATTGCGAAGGCAGCCTACCGGCGCGCAACTGACGCTCATGCACGAAAGCGTGGGTATCGAACAGG\r## ASV3 TACGGAGGATGCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGTAGGCGGGCTGTTAAGTCAGCGGTCAAATGTCGGGGCTCAACCCCGGCCTGCCGTTGAAACTGGCGGCCTCGAGTGGGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACTCCGATTGCGAAGGCAGCATACCGGCGCCCGACTGACGCTGAGGCACGAAAGCGTGGGTATCGAACAGG\r## ASV4 TACGGAGGATGCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGTAGGCGGGCTTTTAAGTCAGCGGTAAAAATTCGGGGCTCAACCCCGTCCGGCCGTTGAAACTGGGGGCCTTGAGTGGGCGAGAAGAAGGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACCCCGATTGCGAAGGCAGCCTTCCGGCGCCCTACTGACGCTGAGGCACGAAAGTGCGGGGATCGAACAGG\r## ASV5 TACGGAGGATCCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGGTGGATTGTTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTGCAGTTGAAACTGGCAGTCTTGAGTACAGTAGAGGTGGGCGGAATTCGTGGTGTAGCGGTGAAATGCTTAGATATCACGAAGAACTCCGATTGCGAAGGCAGCTCACTGGACTGCAACTGACACTGATGCTCGAAAGTGTGGGTATCAAACAGG\r## ASV6 TACGGAGGATGCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGTAGGCGGCCTGCCAAGTCAGCGGTAAAATTGCGGGGCTCAACCCCGTACAGCCGTTGAAACTGCCGGGCTCGAGTGGGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACCCCGATTGCGAAGGCAGCATACCGGCGCCCTACTGACGCTGAGGCACGAAAGTGCGGGGATCAAACAGG\r\n\rAccessing the phylogenetic tree\rWe did not generate a phylogenetic tree during the DADA2 tutorial in the interest of time. However, phyloseq has many excellent tools for working with and visualizing trees. I recommend you take a look at these tutorials below for some examples.\n\rhttps://joey711.github.io/phyloseq/preprocess.html\rhttps://joey711.github.io/phyloseq/plot_tree-examples.html\r\rBen Callahan’s F1000 paper demonstrates a complete analysis workflow in R including the construction of a de-novo phylogenetic tree. I highly recommned you take a look at this paper.\n\n\rAgglomerating and subsetting taxa\rOften times we may want to agglomerate taxa to a specific taxonomic rank for analysis. Or we may want to work with a given subset of taxa. We can perform these operations in phyloseq with the tax_glom and subset_taxa functions.\n(ps_phylum \u0026lt;- tax_glom(ps, \u0026quot;Phylum\u0026quot;))\r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 10 taxa and 19 samples ]\r## sample_data() Sample Data: [ 19 samples by 4 sample variables ]\r## tax_table() Taxonomy Table: [ 10 taxa by 7 taxonomic ranks ]\r## refseq() DNAStringSet: [ 10 reference sequences ]\rtaxa_names(ps_phylum)\r## [1] \u0026quot;ASV1\u0026quot; \u0026quot;ASV11\u0026quot; \u0026quot;ASV19\u0026quot; \u0026quot;ASV53\u0026quot; \u0026quot;ASV67\u0026quot; \u0026quot;ASV90\u0026quot; \u0026quot;ASV107\u0026quot;\r## [8] \u0026quot;ASV109\u0026quot; \u0026quot;ASV189\u0026quot; \u0026quot;ASV191\u0026quot;\rtaxa_names(ps_phylum) \u0026lt;- tax_table(ps_phylum)[, 2]\rtaxa_names(ps_phylum)\r## [1] \u0026quot;Bacteroidetes\u0026quot; \u0026quot;Firmicutes\u0026quot; \u0026quot;Tenericutes\u0026quot; ## [4] \u0026quot;Epsilonbacteraeota\u0026quot; \u0026quot;Actinobacteria\u0026quot; \u0026quot;Patescibacteria\u0026quot; ## [7] \u0026quot;Proteobacteria\u0026quot; \u0026quot;Deinococcus-Thermus\u0026quot; \u0026quot;Cyanobacteria\u0026quot; ## [10] \u0026quot;Verrucomicrobia\u0026quot;\rotu_table(ps_phylum)[1:5, c(1:3, 5, 7)]\r## OTU Table: [5 taxa and 5 samples]\r## taxa are columns\r## Bacteroidetes Firmicutes Tenericutes Actinobacteria Proteobacteria\r## F3D0 3708 2620 151 27 12\r## F3D1 1799 3011 157 3 16\r## F3D141 3437 1370 35 16 0\r## F3D142 2003 452 33 28 0\r## F3D143 1816 655 34 10 0\rHere we are agglomerating the counts to the Phylum-level and then renaming the ASVs to make them more descriptive.\rWe can see that we have 10 Phyla. The ASV information (i.e. refseq and taxonomy for one of the ASVs in each Phylum) gets carried along for the ride (we can typically ignore this or you can remove these components if you prefer).\n\nWe can also subset taxa…\r(ps_bacteroides \u0026lt;- subset_taxa(ps, Genus == \u0026quot;Bacteroides\u0026quot;))\r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 3 taxa and 19 samples ]\r## sample_data() Sample Data: [ 19 samples by 4 sample variables ]\r## tax_table() Taxonomy Table: [ 3 taxa by 7 taxonomic ranks ]\r## refseq() DNAStringSet: [ 3 reference sequences ]\rtax_table(ps_bacteroides)\r## Taxonomy Table: [3 taxa by 7 taxonomic ranks]:\r## Kingdom Phylum Class Order ## ASV5 \u0026quot;Bacteria\u0026quot; \u0026quot;Bacteroidetes\u0026quot; \u0026quot;Bacteroidia\u0026quot; \u0026quot;Bacteroidales\u0026quot;\r## ASV80 \u0026quot;Bacteria\u0026quot; \u0026quot;Bacteroidetes\u0026quot; \u0026quot;Bacteroidia\u0026quot; \u0026quot;Bacteroidales\u0026quot;\r## ASV163 \u0026quot;Bacteria\u0026quot; \u0026quot;Bacteroidetes\u0026quot; \u0026quot;Bacteroidia\u0026quot; \u0026quot;Bacteroidales\u0026quot;\r## Family Genus Species ## ASV5 \u0026quot;Bacteroidaceae\u0026quot; \u0026quot;Bacteroides\u0026quot; NA ## ASV80 \u0026quot;Bacteroidaceae\u0026quot; \u0026quot;Bacteroides\u0026quot; \u0026quot;vulgatus\u0026quot;\r## ASV163 \u0026quot;Bacteroidaceae\u0026quot; \u0026quot;Bacteroides\u0026quot; \u0026quot;vulgatus\u0026quot;\rprune_taxa(taxa_sums(ps) \u0026gt; 100, ps) \r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 99 taxa and 19 samples ]\r## sample_data() Sample Data: [ 19 samples by 4 sample variables ]\r## tax_table() Taxonomy Table: [ 99 taxa by 7 taxonomic ranks ]\r## refseq() DNAStringSet: [ 99 reference sequences ]\rfilter_taxa(ps, function(x) sum(x \u0026gt; 10) \u0026gt; (0.1*length(x)), TRUE) \r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 135 taxa and 19 samples ]\r## sample_data() Sample Data: [ 19 samples by 4 sample variables ]\r## tax_table() Taxonomy Table: [ 135 taxa by 7 taxonomic ranks ]\r## refseq() DNAStringSet: [ 135 reference sequences ]\r\rWith the above commands we can quickly see that we have:\r\rA total of 3 ASVs classified as Bacteroides\rA total of 99 ASVs seen at least 100 times across all samples\rA total of 135 taxa seen at least 10 times in at least 10% of samples\r\r\rThis highlights how we might use phyloseq as a tool to filter taxa prior to statistical analysis.\n\n\r\rSubsetting samples and tranforming counts\rPhyloseq can also be used to subset all the individual components based on sample metadata information. This would take a fair bit of work to do properly if we were working with each individual component…and not with phyloseq. Below we subset the early stool samples. Then we generate an object that includes only samples with \u0026gt; 5,000 total reads.\nps_early \u0026lt;- subset_samples(ps, When == \u0026quot;Early\u0026quot;)\r(ps_early = prune_taxa(taxa_sums(ps_early) \u0026gt; 0, ps_early))\r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 183 taxa and 9 samples ]\r## sample_data() Sample Data: [ 9 samples by 4 sample variables ]\r## tax_table() Taxonomy Table: [ 183 taxa by 7 taxonomic ranks ]\r## refseq() DNAStringSet: [ 183 reference sequences ]\rsample_data(ps_early)$When\r## [1] \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot; \u0026quot;Early\u0026quot;\rsort(sample_sums(ps))\r## F3D143 F3D142 F3D144 F3D5 F3D146 F3D7 F3D150 F3D8 F3D141 F3D1 ## 2518 2521 3488 3716 3879 4217 4240 4547 4863 5017 ## F3D3 F3D145 F3D9 F3D0 F3D6 F3D148 F3D149 F3D147 F3D2 ## 5491 5820 6015 6528 6679 9935 10653 13006 16835\r(ps_reads_GT_5k = prune_samples(sample_sums(ps) \u0026gt; 5000, ps))\r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 232 taxa and 10 samples ]\r## sample_data() Sample Data: [ 10 samples by 4 sample variables ]\r## tax_table() Taxonomy Table: [ 232 taxa by 7 taxonomic ranks ]\r## refseq() DNAStringSet: [ 232 reference sequences ]\rsort(sample_sums(ps_reads_GT_5k))\r## F3D1 F3D3 F3D145 F3D9 F3D0 F3D6 F3D148 F3D149 F3D147 F3D2 ## 5017 5491 5820 6015 6528 6679 9935 10653 13006 16835\r\nCounts can be converted to relative abundances (e.g. total sum scaling) using the transform_sample_counts function. They can also be subsampled/rarified using the rarefy_even_depth function. However, subsampling to account for differences in sequencing depth acorss samples has important limitations. See the papers below for a more in-depth discussion.\n\rMcMurdie and Holmes, Waste Not, Want Not: Why Rarefying Microbiome Data Is Inadmissible\rWeiss et. al., Normalization and microbial differential abundance strategies depend upon data characteristics\r\r\nps_relabund \u0026lt;- transform_sample_counts(ps, function(x) x / sum(x))\rotu_table(ps_relabund)[1:5, 1:5]\r## OTU Table: [5 taxa and 5 samples]\r## taxa are columns\r## ASV1 ASV2 ASV3 ASV4 ASV5\r## F3D0 0.08869485 0.05284926 0.06878064 0.06587010 0.02359069\r## F3D1 0.08072553 0.07036077 0.04604345 0.01375324 0.02790512\r## F3D141 0.09130167 0.07443965 0.07094386 0.10322846 0.03886490\r## F3D142 0.11463705 0.12058707 0.06267354 0.06505355 0.07140024\r## F3D143 0.09054805 0.06989674 0.08101668 0.09173948 0.05162828\r(ps_rare \u0026lt;- rarefy_even_depth(ps, sample.size = 4000, rngseed = 123, replace = FALSE))\r## `set.seed(123)` was used to initialize repeatable random subsampling.\r## Please record this for your records so others can reproduce.\r## Try `set.seed(123); .Random.seed` for the full vector\r## ...\r## 5 samples removedbecause they contained fewer reads than `sample.size`.\r## Up to first five removed samples are:\r## F3D142F3D143F3D144F3D146F3D5\r## ...\r## 15OTUs were removed because they are no longer ## present in any sample after random subsampling\r## ...\r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 217 taxa and 14 samples ]\r## sample_data() Sample Data: [ 14 samples by 4 sample variables ]\r## tax_table() Taxonomy Table: [ 217 taxa by 7 taxonomic ranks ]\r## refseq() DNAStringSet: [ 217 reference sequences ]\rsample_sums(ps_rare)\r## F3D0 F3D1 F3D141 F3D145 F3D147 F3D148 F3D149 F3D150 F3D2 F3D3 ## 4000 4000 4000 4000 4000 4000 4000 4000 4000 4000 ## F3D6 F3D7 F3D8 F3D9 ## 4000 4000 4000 4000\r\n\rExample analytic and graphical capabilities\rPhyloseq has an extensive list of functions for processing and analyzing microbiome data. I recommend you view the tutorial section on the phyloseq home page to get a feel for all that phyloseq can do. Below are just a few quick examples. We will get more into these types of analyses in subsequent sessions.\nAlpha-diversity\rBelow we will receive a warning that our data does not contain any singletons and that the results of richness estimates are probably unreliable. This is an important point and we will delve into this issue more in the next session. For now, you can go ahead and ignore the warning.\nhead(estimate_richness(ps))\r## Warning in estimate_richness(ps): The data you have provided does not have\r## any singletons. This is highly suspicious. Results of richness\r## estimates (for example) are probably unreliable, or wrong, if you have already\r## trimmed low-abundance taxa from the data.\r## ## We recommended that you find the un-trimmed data and retry.\r## Observed Chao1 se.chao1 ACE se.ACE Shannon Simpson InvSimpson\r## F3D0 106 106 0 106 4.539138 3.865881 0.9644889 28.16024\r## F3D1 100 100 0 100 4.208325 3.993196 0.9709838 34.46347\r## F3D141 74 74 0 74 3.878214 3.428895 0.9501123 20.04502\r## F3D142 48 48 0 48 3.388092 3.117940 0.9386949 16.31185\r## F3D143 56 56 0 56 3.543102 3.292717 0.9464422 18.67141\r## F3D144 47 47 0 47 3.135249 2.994201 0.9309895 14.49054\r## Fisher\r## F3D0 17.973004\r## F3D1 17.696857\r## F3D141 12.383762\r## F3D142 8.412094\r## F3D143 10.148818\r## F3D144 7.678694\r(p \u0026lt;- plot_richness(ps, x = \u0026quot;When\u0026quot;, color = \u0026quot;When\u0026quot;, measures = c(\u0026quot;Observed\u0026quot;, \u0026quot;Shannon\u0026quot;)))\r## Warning in estimate_richness(physeq, split = TRUE, measures = measures): The data you have provided does not have\r## any singletons. This is highly suspicious. Results of richness\r## estimates (for example) are probably unreliable, or wrong, if you have already\r## trimmed low-abundance taxa from the data.\r## ## We recommended that you find the un-trimmed data and retry.\rp + labs(x = \u0026quot;\u0026quot;, y = \u0026quot;Alpha Diversity Measure\\n\u0026quot;) + theme_bw()\r\rBeta-diversity ordination\rps_rare_bray \u0026lt;- ordinate(ps_rare, \u0026quot;NMDS\u0026quot;, \u0026quot;bray\u0026quot;)\r## Square root transformation\r## Wisconsin double standardization\r## Run 0 stress 0.08484704 ## Run 1 stress 0.08484704 ## ... New best solution\r## ... Procrustes: rmse 2.497137e-06 max resid 5.691675e-06 ## ... Similar to previous best\r## Run 2 stress 0.09657264 ## Run 3 stress 0.08484704 ## ... Procrustes: rmse 7.186183e-07 max resid 1.423558e-06 ## ... Similar to previous best\r## Run 4 stress 0.08484704 ## ... Procrustes: rmse 3.303025e-06 max resid 7.565974e-06 ## ... Similar to previous best\r## Run 5 stress 0.1744901 ## Run 6 stress 0.08484704 ## ... Procrustes: rmse 1.008148e-06 max resid 2.038791e-06 ## ... Similar to previous best\r## Run 7 stress 0.08484704 ## ... Procrustes: rmse 1.776536e-06 max resid 3.520974e-06 ## ... Similar to previous best\r## Run 8 stress 0.09657264 ## Run 9 stress 0.08484704 ## ... Procrustes: rmse 8.550518e-07 max resid 1.794331e-06 ## ... Similar to previous best\r## Run 10 stress 0.08484704 ## ... Procrustes: rmse 1.376679e-06 max resid 2.816876e-06 ## ... Similar to previous best\r## Run 11 stress 0.08484704 ## ... Procrustes: rmse 4.702272e-06 max resid 8.17489e-06 ## ... Similar to previous best\r## Run 12 stress 0.08484704 ## ... New best solution\r## ... Procrustes: rmse 2.157179e-07 max resid 4.2813e-07 ## ... Similar to previous best\r## Run 13 stress 0.08484704 ## ... Procrustes: rmse 1.726469e-06 max resid 3.270828e-06 ## ... Similar to previous best\r## Run 14 stress 0.08484704 ## ... Procrustes: rmse 1.055175e-06 max resid 2.649077e-06 ## ... Similar to previous best\r## Run 15 stress 0.09657265 ## Run 16 stress 0.1751066 ## Run 17 stress 0.08484704 ## ... Procrustes: rmse 6.953774e-07 max resid 1.374792e-06 ## ... Similar to previous best\r## Run 18 stress 0.09584961 ## Run 19 stress 0.08484704 ## ... Procrustes: rmse 5.428812e-06 max resid 1.248684e-05 ## ... Similar to previous best\r## Run 20 stress 0.1795526 ## *** Solution reached\rplot_ordination(ps_rare, ps_rare_bray, type=\u0026quot;samples\u0026quot;, color=\u0026quot;When\u0026quot;) + geom_point(size = 3) \r\rStacked bar plots\rplot_bar(ps, fill=\u0026quot;Phylum\u0026quot;)\rplot_bar(ps_relabund, fill=\u0026quot;Phylum\u0026quot;) + geom_bar(aes(color = Phylum, fill = Phylum), stat=\u0026quot;identity\u0026quot;, position=\u0026quot;stack\u0026quot;) +\rlabs(x = \u0026quot;\u0026quot;, y = \u0026quot;Relative Abundance\\n\u0026quot;) +\rtheme(panel.background = element_blank())\r\rHeatmaps\r(ps_fam \u0026lt;- tax_glom(ps, \u0026quot;Family\u0026quot;))\r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 33 taxa and 19 samples ]\r## sample_data() Sample Data: [ 19 samples by 4 sample variables ]\r## tax_table() Taxonomy Table: [ 33 taxa by 7 taxonomic ranks ]\r## refseq() DNAStringSet: [ 33 reference sequences ]\r(ps_fam_rare \u0026lt;- rarefy_even_depth(ps_fam, sample.size = 4000, rngseed = 123, replace = FALSE))\r## `set.seed(123)` was used to initialize repeatable random subsampling.\r## Please record this for your records so others can reproduce.\r## Try `set.seed(123); .Random.seed` for the full vector\r## ...\r## 5 samples removedbecause they contained fewer reads than `sample.size`.\r## Up to first five removed samples are:\r## F3D142F3D143F3D144F3D146F3D5\r## ...\r## 9OTUs were removed because they are no longer ## present in any sample after random subsampling\r## ...\r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 24 taxa and 14 samples ]\r## sample_data() Sample Data: [ 14 samples by 4 sample variables ]\r## tax_table() Taxonomy Table: [ 24 taxa by 7 taxonomic ranks ]\r## refseq() DNAStringSet: [ 24 reference sequences ]\rplot_heatmap(ps_fam_rare, sample.label = \u0026quot;When\u0026quot;, taxa.label = \u0026quot;Family\u0026quot;)\r## Warning: Transformation introduced infinite values in discrete y-axis\r\r\r","date":1564272000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564367031,"objectID":"cec21b24eafe3bd9f42f5d7970a8e406","permalink":"/post/introduction-to-phyloseq/","publishdate":"2019-07-28T00:00:00Z","relpermalink":"/post/introduction-to-phyloseq/","section":"post","summary":"This post is from a tutorial demonstrating the processing of amplicon short read data in R taught as part of the Introduction to Metagenomics Summer Workshop. It provides a quick introduction some of the functionality provided by phyloseq and follows some of Paul McMurdie’s excellent tutorials. This tutorial picks up where Ben Callahan’s DADA2 tutorial leaves off and highlights some of the main accessor and processor functions of the package.","tags":["Microbiome","R","Phyloseq","DADA2"],"title":"Introduction to Phyloseq","type":"post"},{"authors":[],"categories":["Microbiome"],"content":"\r\r\nThis post is also from the Introduction to Metagenomics Summer Workshop and provides a quick introduction to some common analytic methods used to analyze microbiome data. I thought it might be of interest to a broader audience so decided to post it here.\n\nThe goal of this session is to provide you with a high-level introduction to some common analytic methods used to analyze microbiome data. It will also serve to introduce you several popular R packages developed specifically for microbiome data analysis. We chose to emphasize R for this course because of the rapid development of methods and packages provided in the R language, the breadth of existing tutorials and resources, and the ever expanding community of R users. However, other platforms such as QIIME2, biobakery and USEARCH, just to name a few, offer excellent integrated solutions for the processing and analysis of amplicon and/or shotgun metagenomic sequence data.\nThe diverse goals and technical variation of metagenomic research projects does not allow for a standard “analytic pipeline” for microbiome data analysis. Approaching the analysis of microbiome data with a single workflow in mind is generally not a great idea, as there is no “one size fits all” solution for the assorted set of questions one might want to answer. However, you may be surprised to find that projects on very different topics often have overarching analytic aims such as:\n\rDescribing the microbial community composition of a set of samples\rEstimating within- and between-sample diversity\rIdentifying differentially abundant taxa\rPredicting a response from a set of taxonomic features\rAssessing microbial network structures and patterns of co-occurance\rExploring the phylogenetic relatedness of a set of organisms\r\rWe will cover statistical methods developed to address several of these aims with a focus on introducing you to their implementation in R. A detailed description of each approach, its assumptions, package options, etc. is beyond the scope of this session. However, I try to provide links to source materials and more detailed documentation where possible. The statistical analysis of microbial metagenomic sequence data is a rapidly evolving field and different solutions (often many) have been proposed to answer the same questions. I have tried to focus on methods that are common in the microbiome literature, well-documented, and reasonably accessible…and a few I think are new and interesting. I also try to show a few different approaches in each section. In cases where I focus largely on more basic implementations, I have tried to provide links for advanced learning of more complex topics.\n\nThe publicly available data used in this session are from Giloteaux et. al. Reduced diversity and altered composition of the gut microbiome in individuals with myalgic encephalomyelitis/chronic fatigue syndrome published in Microbiome (2016). The metadata, OTU table, and taxonomy files were obtained from the QIIME2 tutorial Differential abundance analysis with gneiss (accessed on 06/13/2019). The code and data used to generate the phyloseq object is provided on my GitHub page.\rThe data were generated by 16S rRNA gene sequencing (V4 hypervariable region) of fecal samples on the Illumina MiSeq. Our focus will be on examining differences in the microbiota of patients with chronic fatigue syndrome versus healthy controls. We will examine:\n\rTaxonomic relative abundance\rHierarchal clustering\rAlpha-diversity\rBeta-diversity\rDifferential abundance testing\rPredicting class labels\r\r\n\rAdditional resources\rThere are many great resources for conducting microbiome data analysis in R. Statistical Analysis of Microbiome Data in R by Xia, Sun, and Chen (2018) is an excellent textbook in this area. For those looking for an end-to-end workflow for amplicon data in R, I highly recommend Ben Callahan’s F1000 Research paper Bioconductor Workflow for Microbiome Data Analysis: from raw reads to community analyses. In addition there are numerous websites and vignettes dedicated to microbiome analyses. A few include:\n\rPaul McMurdie’s phyloseq website\rRobert Edgar’s website\rThe microbiome R package website\rAll the materials and resources posted on the STAMPS wiki page (a course I highly recommend!)\r\r\n\rInstalling packages\rThe code below will install the packages needed to run the analyses. These packages are installed from CRAN, Bioconductor and from developer GitHub sites. Several of these packages are large, and have many dependencies, so this will take some time. This code was modified from Ben’s Bioconductor paper.\nIn general, package management and versioning can be a challenge for those new to R. Inevitably, if you do not take steps ahead of time, you will find that one of your programs that ran fine just a few months ago, no longer works! Often this is because changes in new versions of packages or R caused your code to break. There are multiple solutions depending on your goals, and all come with pros and cons, but a good place to start is to learn more about Packrat and other package management tools.\nIf you already have many/some of these packages installed on your local system, you may want to skip this step and install manually only those that you need.\n.cran_packages \u0026lt;- c(\u0026quot;tidyverse\u0026quot;, \u0026quot;cowplot\u0026quot;, \u0026quot;picante\u0026quot;, \u0026quot;vegan\u0026quot;, \u0026quot;HMP\u0026quot;, \u0026quot;dendextend\u0026quot;, \u0026quot;rms\u0026quot;, \u0026quot;devtools\u0026quot;)\r.bioc_packages \u0026lt;- c(\u0026quot;phyloseq\u0026quot;, \u0026quot;DESeq2\u0026quot;, \u0026quot;microbiome\u0026quot;, \u0026quot;metagenomeSeq\u0026quot;, \u0026quot;ALDEx2\u0026quot;)\r.inst \u0026lt;- .cran_packages %in% installed.packages()\rif(any(!.inst)) {\rinstall.packages(.cran_packages[!.inst])\r}\rif (!requireNamespace(\u0026quot;BiocManager\u0026quot;, quietly = TRUE))\rinstall.packages(\u0026quot;BiocManager\u0026quot;)\rBiocManager::install(.bioc_packages, version = \u0026quot;3.9\u0026quot;)\rdevtools::install_github(\u0026quot;adw96/breakaway\u0026quot;)\rdevtools::install_github(repo = \u0026quot;UVic-omics/selbal\u0026quot;)\r\n\rLoading required packages\rLet’s load the required packages. This is not the most elegant way to do this, but it allows you to see each package that is loaded and the version number.\nlibrary(tidyverse); packageVersion(\u0026quot;tidyverse\u0026quot;) \r## [1] \u0026#39;1.2.1\u0026#39;\rlibrary(phyloseq); packageVersion(\u0026quot;phyloseq\u0026quot;) \r## [1] \u0026#39;1.28.0\u0026#39;\rlibrary(DESeq2); packageVersion(\u0026quot;DESeq2\u0026quot;) \r## [1] \u0026#39;1.24.0\u0026#39;\rlibrary(microbiome); packageVersion(\u0026quot;microbiome\u0026quot;) \r## [1] \u0026#39;1.6.0\u0026#39;\rlibrary(vegan); packageVersion(\u0026quot;vegan\u0026quot;) \r## [1] \u0026#39;2.5.5\u0026#39;\rlibrary(picante); packageVersion(\u0026quot;picante\u0026quot;) \r## [1] \u0026#39;1.8\u0026#39;\rlibrary(ALDEx2); packageVersion(\u0026quot;ALDEx2\u0026quot;) \r## [1] \u0026#39;1.16.0\u0026#39;\rlibrary(metagenomeSeq); packageVersion(\u0026quot;metagenomeSeq\u0026quot;) \r## [1] \u0026#39;1.26.0\u0026#39;\rlibrary(HMP); packageVersion(\u0026quot;HMP\u0026quot;) \r## [1] \u0026#39;1.6\u0026#39;\rlibrary(dendextend); packageVersion(\u0026quot;dendextend\u0026quot;) \r## [1] \u0026#39;1.12.0\u0026#39;\rlibrary(selbal); packageVersion(\u0026quot;selbal\u0026quot;) \r## [1] \u0026#39;0.1.0\u0026#39;\rlibrary(rms); packageVersion(\u0026quot;rms\u0026quot;)\r## [1] \u0026#39;5.1.3.1\u0026#39;\rlibrary(breakaway); packageVersion(\u0026quot;breakaway\u0026quot;) \r## [1] \u0026#39;4.6.8\u0026#39;\r\n\rReading in the Giloteaux data\rThe data from the Giloteaux et. al. 2016 paper has been saved as a phyloseq object. We will use the readRDS() function to read it into R. We will also examine the distribution of read counts (per sample library size/read depth/total reads) and remove samples with \u0026lt; 5k total reads. We will then create a new metadata field “Status” that provides more “descriptive” values for our primary variable of interest; whether or not the sample was from a patient with chronic fatigue syndrome or a healthy control.\nThis should all be familiar to those of you who worked through the Introduction to Phyloseq session. However, something that will be new is that now we are using pipes from the magrittr package and tidyverse verbs to streamline some of the data manipulation steps. For those of you have not worked with the tidyverse set of packages and functions you are missing out! They will change they way you work in R. R for Data Science is an excellent source to learn more about the tidyverse packages and philosophy for data science.\nAdditional quality controls checks and data pre-processing specific to the goals of your project should be conducted at this point (but is outside of the scope of the current session).\n#Read in ps object\r(ps \u0026lt;- readRDS(\u0026quot;C:/Users/olljt2/Desktop/academic_web_page/static/data/ps_giloteaux_2016.rds\u0026quot;))\r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 138 taxa and 87 samples ]\r## sample_data() Sample Data: [ 87 samples by 22 sample variables ]\r## tax_table() Taxonomy Table: [ 138 taxa by 7 taxonomic ranks ]\r## phy_tree() Phylogenetic Tree: [ 138 tips and 137 internal nodes ]\r## refseq() DNAStringSet: [ 138 reference sequences ]\r#Sort samples on total read count, remove \u0026lt;5k reads, remove any OTUs seen in only those samples\rsort(phyloseq::sample_sums(ps)) \r## ERR1331827 ERR1331852 ERR1331856 ERR1331869 ERR1331833 ERR1331797 ## 2707 3031 3117 5083 5245 5307 ## ERR1331786 ERR1331818 ERR1331792 ERR1331803 ERR1331793 ERR1331819 ## 5696 5733 6463 6512 6622 6900 ## ERR1331858 ERR1331807 ERR1331815 ERR1331821 ERR1331843 ERR1331795 ## 6913 7121 7179 7272 7284 7314 ## ERR1331846 ERR1331811 ERR1331845 ERR1331842 ERR1331838 ERR1331855 ## 7569 7665 7815 7911 8102 8115 ## ERR1331824 ERR1331832 ERR1331804 ERR1331868 ERR1331831 ERR1331859 ## 8148 8186 8236 8612 8840 9016 ## ERR1331790 ERR1331789 ERR1331837 ERR1331857 ERR1331801 ERR1331841 ## 9085 9184 9731 9966 11173 11442 ## ERR1331861 ERR1331820 ERR1331854 ERR1331863 ERR1331806 ERR1331787 ## 11826 12940 13029 13094 13095 13690 ## ERR1331853 ERR1331851 ERR1331836 ERR1331835 ERR1331802 ERR1331799 ## 14113 14365 14488 14753 14799 14833 ## ERR1331847 ERR1331834 ERR1331817 ERR1331809 ERR1331828 ERR1331813 ## 15290 15367 15460 16162 16494 16749 ## ERR1331798 ERR1331816 ERR1331830 ERR1331785 ERR1331823 ERR1331865 ## 16947 17015 17457 17557 18506 19013 ## ERR1331848 ERR1331800 ERR1331867 ERR1331870 ERR1331810 ERR1331825 ## 19257 19443 19732 19783 19909 20069 ## ERR1331866 ERR1331871 ERR1331849 ERR1331860 ERR1331808 ERR1331872 ## 20760 20862 21540 21553 21713 22339 ## ERR1331812 ERR1331850 ERR1331791 ERR1331788 ERR1331796 ERR1331840 ## 22518 22639 23246 23751 23792 24752 ## ERR1331826 ERR1331822 ERR1331862 ERR1331864 ERR1331829 ERR1331844 ## 28186 28556 31064 44533 51918 57214 ## ERR1331805 ERR1331839 ERR1331794 ## 59355 61206 65941\r(ps \u0026lt;- phyloseq::subset_samples(ps, phyloseq::sample_sums(ps) \u0026gt; 5000)) \r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 138 taxa and 84 samples ]\r## sample_data() Sample Data: [ 84 samples by 22 sample variables ]\r## tax_table() Taxonomy Table: [ 138 taxa by 7 taxonomic ranks ]\r## phy_tree() Phylogenetic Tree: [ 138 tips and 137 internal nodes ]\r## refseq() DNAStringSet: [ 138 reference sequences ]\r(ps \u0026lt;- phyloseq::prune_taxa(phyloseq::taxa_sums(ps) \u0026gt; 0, ps)) \r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 138 taxa and 84 samples ]\r## sample_data() Sample Data: [ 84 samples by 22 sample variables ]\r## tax_table() Taxonomy Table: [ 138 taxa by 7 taxonomic ranks ]\r## phy_tree() Phylogenetic Tree: [ 138 tips and 137 internal nodes ]\r## refseq() DNAStringSet: [ 138 reference sequences ]\r#Assign new sample metadata field\rphyloseq::sample_data(ps)$Status \u0026lt;- ifelse(phyloseq::sample_data(ps)$Subject == \u0026quot;Patient\u0026quot;, \u0026quot;Chronic Fatigue\u0026quot;, \u0026quot;Control\u0026quot;)\rphyloseq::sample_data(ps)$Status \u0026lt;- factor(phyloseq::sample_data(ps)$Status, levels = c(\u0026quot;Control\u0026quot;, \u0026quot;Chronic Fatigue\u0026quot;))\rps %\u0026gt;% sample_data %\u0026gt;%\rdplyr::count(Status)\r## # A tibble: 2 x 2\r## Status n\r## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt;\r## 1 Control 37\r## 2 Chronic Fatigue 47\rWe can see that we have a phyloseq object consisting of 138 taxa on 84 samples, 22 sample metadata fields, 7 taxonomic ranks and that a phylogenetic tree and the reference sequences have been included. We also see that there are data on n=37 controls and n=47 patients with chronic fatigue.\n\n\rVisualizing relative abundance\rOften an early step in many microbiome projects to visualize the relative abundance of organisms at specific taxonomic ranks. Stacked bar plots and faceted box plots are two ways of doing this. I recommend that if using bar plots to include each sample as a separate observation (and not to aggregate by groups). This is because the sample-to-sample variability can be high, even within groups, which may be just or more important to observe than between-group differences…which can be obscured with aggregation.\nThe ability to discriminate between more than say a dozen colors in a single plot is also a limitation of the stacked bar plot (faceted box plots do not suffer this limitation). Thus, this is one analysis I often run in QIIME2 using the taxa barplot command, as it allows for beautiful interactive viewing. This could also be done in R using a shiny app. I just haven’t implemented, or seen others implement, this functionality yet in R (I imagine someone has so please let me know if/when you do).\nHere we will agglomerate the reads to the phylum-level using phyloseq and plot the relative abundance by Status.\n#Get count of phyla\rtable(phyloseq::tax_table(ps)[, \u0026quot;Phylum\u0026quot;])\r## ## Actinobacteria Bacteroidetes Cyanobacteria Euryarchaeota ## 7 11 2 1 ## Firmicutes Fusobacteria Proteobacteria Tenericutes ## 105 1 7 2 ## Verrucomicrobia ## 1\r#Convert to relative abundance\rps_rel_abund = phyloseq::transform_sample_counts(ps, function(x){x / sum(x)})\rphyloseq::otu_table(ps)[1:5, 1:5]\r## OTU Table: [5 taxa and 5 samples]\r## taxa are rows\r## ERR1331793 ERR1331872 ERR1331819 ERR1331794 ERR1331851\r## OTU1 2 581 347 916 10498\r## OTU2 371 46 0 233 301\r## OTU3 1189 81 637 199 0\r## OTU4 0 172 246 0 372\r## OTU5 308 44 143 155 221\rphyloseq::otu_table(ps_rel_abund)[1:5, 1:5]\r## OTU Table: [5 taxa and 5 samples]\r## taxa are rows\r## ERR1331793 ERR1331872 ERR1331819 ERR1331794 ERR1331851\r## OTU1 0.0003020236 0.026008326 0.05028986 0.013891206 0.73080404\r## OTU2 0.0560253700 0.002059179 0.00000000 0.003533462 0.02095371\r## OTU3 0.1795530051 0.003625946 0.09231884 0.003017849 0.00000000\r## OTU4 0.0000000000 0.007699539 0.03565217 0.000000000 0.02589628\r## OTU5 0.0465116279 0.001969649 0.02072464 0.002350586 0.01538462\r#Plot\rphyloseq::plot_bar(ps_rel_abund, fill = \u0026quot;Phylum\u0026quot;) +\rgeom_bar(aes(color = Phylum, fill = Phylum), stat = \u0026quot;identity\u0026quot;, position = \u0026quot;stack\u0026quot;) +\rlabs(x = \u0026quot;\u0026quot;, y = \u0026quot;Relative Abundance\\n\u0026quot;) +\rfacet_wrap(~ Status, scales = \u0026quot;free\u0026quot;) +\rtheme(panel.background = element_blank(),\raxis.text.x=element_blank(),\raxis.ticks.x=element_blank())\rThere are a total of nine phyla and their relative abundance looks to be quite simialr between groups. You could sort the taxa on abundance to improve the vizualization. I’ll let you give that a shot on your own. Let’s generate box plots according to group and facet them by phylum using the raw counts. We will use the phyloseq::melt function to help.\n\n#Agglomerate to phylum-level and rename\rps_phylum \u0026lt;- phyloseq::tax_glom(ps, \u0026quot;Phylum\u0026quot;)\rphyloseq::taxa_names(ps_phylum) \u0026lt;- phyloseq::tax_table(ps_phylum)[, \u0026quot;Phylum\u0026quot;]\rphyloseq::otu_table(ps_phylum)[1:5, 1:5]\r## OTU Table: [5 taxa and 5 samples]\r## taxa are rows\r## ERR1331793 ERR1331872 ERR1331819 ERR1331794 ERR1331851\r## Bacteroidetes 1903 878 1837 1969 11776\r## Proteobacteria 119 3315 468 62358 319\r## Firmicutes 4319 14429 3548 1609 2207\r## Actinobacteria 30 976 17 0 58\r## Cyanobacteria 246 0 0 0 0\r#Melt and plot\rphyloseq::psmelt(ps_phylum) %\u0026gt;%\rggplot(data = ., aes(x = Status, y = Abundance)) +\rgeom_boxplot(outlier.shape = NA) +\rgeom_jitter(aes(color = OTU), height = 0, width = .2) +\rlabs(x = \u0026quot;\u0026quot;, y = \u0026quot;Abundance\\n\u0026quot;) +\rfacet_wrap(~ OTU, scales = \u0026quot;free\u0026quot;)\rAs we saw before, many samples have a high number of Firmicutes, followed by Bacteroidetes, and Actinobacteria. Most samples have low read counts for other phyla with some outlying samples. There does not appear to be much difference in the major phyla between groups. Check out Ben Callahan’s F1000 paper for additional examples on visualizing sequence variant prevalence/abundance that may be helpful for specific analyses.\nOne way to formally test for a difference in the phylum-level abundance is to conduct a multivariate test for differences in the overall composition between groups of samples. This type of test can be implemented using the HMP package (Xdc.sevsample function) described in the paper Hypothesis Testing and Power Calculations for Taxonomic-Based Human Microbiome Data by La Rosa et. al.\nBasically, a Dirichlet-Multinomial distribution is assumed for the data and null hypothesis testing is conducted by testing for a difference in the location (mean distribution of each taxa) across groups accounting for the overdispersion in the count data. The authors describe this test as analogous to a two sample t-test, but instead we are evaluating whether taxa frequencies observed in both groups of metagenomic samples are equal (null hypothesis). Here we are performing the test on bacterial phyla, but it could be performed at any taxonomic level including OTUs. The authors recommend that rare taxa be pooled into a single group to improve testing.\n#Subset groups\rcontrols \u0026lt;- phyloseq::subset_samples(ps_phylum, Status == \u0026quot;Control\u0026quot;)\rcf \u0026lt;- phyloseq::subset_samples(ps_phylum, Status == \u0026quot;Chronic Fatigue\u0026quot;)\r#Output OTU tables\rcontrol_otu \u0026lt;- data.frame(phyloseq::otu_table(controls))\rcf_otu \u0026lt;- data.frame(phyloseq::otu_table(cf))\r#Group rare phyla\rcontrol_otu \u0026lt;- control_otu %\u0026gt;%\rt(.) %\u0026gt;%\ras.data.frame(.) %\u0026gt;%\rmutate(Other = Cyanobacteria + Euryarchaeota + Tenericutes + Verrucomicrobia + Fusobacteria) %\u0026gt;%\rdplyr::select(-Cyanobacteria, -Euryarchaeota, -Tenericutes, -Verrucomicrobia, -Fusobacteria)\rcf_otu \u0026lt;- cf_otu %\u0026gt;%\rt(.) %\u0026gt;%\ras.data.frame(.) %\u0026gt;%\rmutate(Other = Cyanobacteria + Euryarchaeota + Tenericutes + Verrucomicrobia + Fusobacteria) %\u0026gt;%\rdplyr::select(-Cyanobacteria, -Euryarchaeota, -Tenericutes, -Verrucomicrobia, -Fusobacteria)\r#HMP test\rgroup_data \u0026lt;- list(control_otu, cf_otu)\r(xdc \u0026lt;- HMP::Xdc.sevsample(group_data)) \r## $`Xdc statistics`\r## [1] 0.2769004\r## ## $`p value`\r## [1] 0.9980551\r1 - pchisq(.2769004, 5)\r## [1] 0.9980551\rThe HMP test fails to reject the null hypothesis of no difference in the distribution of phyla between groups (in line with our expectations). The xdc test follows a Chi-square distribution with degrees of freedom equal to (J-1)*K, where J is the number of groups and K is the number of taxa. The last calculation just shows how the p-value is obtained. The test can be expanded to more than two groups and to test for differences in rank abundance distributions (RAD). These are topics I encourage you to explore on your own.\rThe microbiome package also has some nice functions for visualizing community composition you should look into.\n\n\rHierarchical clustering\rAnother early step in many microbiome projects to examine how samples cluster on some measure of taxonomic (dis)similarity. There are MANY ways to do perform such clustering. Here I present just one approach that I assume many of you are familiar with. We will perform hierarchal clustering of samples based on their Bray-Curtis dissimilarity. Here is a link to how it is calculated. We will discuss this in more detail during the lecture, but for now it should suffice to know that the as two samples share fewer taxa, the number increases. The Bray-Curtis dissimilarity is zero for samples that have the exact same composition and one for those sharing no taxa. It is also worth remembering that this is a measure of dissimilarity (it is not a true distance measure).\nWe will use the popular vegan package for community ecology to compute the Bray-Curtis dissimilarity for all samples. Then we will apply Ward’s clustering and color code the sample names to assess the extent to which the samples from the control and chronic fatigue participants cluster. At a high-level, Ward’s clustering finds the pair of clusters at each iteration that minimalizes the increase in total variance.\nLet’s see how this is done in R.\n#Extract OTU table and compute BC\rps_rel_otu \u0026lt;- data.frame(phyloseq::otu_table(ps_rel_abund))\rps_rel_otu \u0026lt;- t(ps_rel_otu)\rbc_dist \u0026lt;- vegan::vegdist(ps_rel_otu, method = \u0026quot;bray\u0026quot;)\ras.matrix(bc_dist)[1:5, 1:5]\r## ERR1331793 ERR1331872 ERR1331819 ERR1331794 ERR1331851\r## ERR1331793 0.0000000 0.8801040 0.5975550 0.9767218 0.8684629\r## ERR1331872 0.8801040 0.0000000 0.7590766 0.9596181 0.9206484\r## ERR1331819 0.5975550 0.7590766 0.0000000 0.9556656 0.7810736\r## ERR1331794 0.9767218 0.9596181 0.9556656 0.0000000 0.9693291\r## ERR1331851 0.8684629 0.9206484 0.7810736 0.9693291 0.0000000\r#Save as dendrogram\rward \u0026lt;- as.dendrogram(hclust(bc_dist, method = \u0026quot;ward.D2\u0026quot;))\r#Provide color codes\rmeta \u0026lt;- data.frame(phyloseq::sample_data(ps_rel_abund))\rcolorCode \u0026lt;- c(Control = \u0026quot;red\u0026quot;, `Chronic Fatigue` = \u0026quot;blue\u0026quot;)\rlabels_colors(ward) \u0026lt;- colorCode[meta$Status][order.dendrogram(ward)]\r#Plot\rplot(ward)\rWe can see that the Bray-Curtis dissimilarity for these selected samples range from around 0.6 to close to 1. Thus, the composition of some samples are quite different from one another. We also see some clustering according to Status near the tips, but no clear “higher-level” clustering. We will try to exploit this information later to see if we can predict the label of each sample with only information on the microbial relative abundances.\nHeatmaps are another good way to visualize these types of associations and can be implemented using phyloseq. Give it a try on your own!\n\n\rAlpha-diversity\rRobert Edgar provides an excellent definition of alpha-diversity on his website:\n\rAlpha-diversity is the diversity in a single ecosystem or sample. The simplest measure is richness, the number of species (or OTUs) observed in the sample. Other metrics consider the abundances (frequencies) of the OTUs, for example to give lower weight to lower-abundance OTUs.\n\rBasically, it is the within-sample diversity and includes how many organisms are observed (i.e. observed OTUs) and how evenly they are distributed. Many researchers are interested in estimating alpha-diversity since differences between groups have been associated with several health related outcomes. However the issue of how to best estimate these quantities using data derived from next-generation sequencing (NGS) is controversial. This is due to two main reasons:\nThe observed richness in a sample/site is typically underestimated due to inexhaustive sampling. Thus, valid estimators of diversity require extrapolating from the available observations to provide estimates of the unobserved taxa (and also account for the sampling variability).\rExtrapolation estimators require an accurate count of the rare taxa (including singletons) in each sample…which for NGS-based metagenomics studies we typically do not have…since singletons generally cannot be differentiated from sequencing errors using the current best informatics workflows. The extent to which we cannot accurately detect low abundance taxa limits the utility of diversity estimators reliant upon such counts.\r\rSo we are kind of in a catch-22 regarding the best way forward given current technologies.\nIt has been argued; however, that diversity metrics can nevertheless be compared between samples because the errors and biases are mostly systematic (i.e. occur with similar rates in all samples). See Dr. Edgar’s discussion of the topic here for more detail. This is what is typically done in most published studies to date. A major underlying assumption here is that abundance structures are the same for the two groups being compared. This is perhaps a reasonable assumption when comparing similar environments, but it is hard to know without exhaustive sampling. See figure 1 here and the related discussion by Amy Willis for a more detailed understanding of how the abundance structure can lead you to incorrect conclusions (quite disconcerting).\nRarefaction (subsampling reads from each sample without replacement to a constant depth) is often performed before estimating alpha-diversity; although, it is unclear to me if/when this helps since environments can be identical with respect to one alpha diversity metric, but the different abundance structures will induce different biases when rarified (italicized text taken from Amy’s paper linked to above).\nDr. Willis has examined this issue in depth and developed breakaway and DivNet to specifically address the shortcoming of current approaches. I highly recommend you check out her GitHub site. In a recent paper she argues:\n\rIn order to draw meaningful conclusions about the entire microbial community, it is necessary to adjust for inexhaustive sampling using statistically-motivated parameter estimates for alpha diversity. In order to draw meaningful conclusions regarding comparisons of microbial communities, it is necessary to use measurement error models to adjust for the uncertainty in the estimation of alpha diversity.\rShe also states that breakaway is not overly sensitive to singleton counts.\n\rThe links below provide a brief introduction to the topic. I look forward to Amy’s updated tutorial and thoughts on when microbial diversity estimation is, and isn’t, possible as mentioned in the last link (I suspect it will result in some updating of these materials).\n\rhttps://www.drive5.com/usearch/manual/alpha_diversity.html\rhttps://www.biorxiv.org/content/biorxiv/early/2017/12/11/231878.full.pdf\rhttps://github.com/benjjneb/dada2/issues/103\rhttps://github.com/benjjneb/dada2/issues/317\r\r\nBelow we will estimate and test for differences according to chronic fatigue status using the plug-in estimates for observed richness, Shannon diversity, and phylogenetic diversity on the subsampled data (since this is common practice). I have also provided some code to estimate richness using breakaway that you can examine on your own. I plan to update this section with some data that is more appropriate for breakaway. So check back soon.\nggplot(data = data.frame(\u0026quot;total_reads\u0026quot; = phyloseq::sample_sums(ps),\r\u0026quot;observed\u0026quot; = phyloseq::estimate_richness(ps, measures = \u0026quot;Observed\u0026quot;)[, 1]),\raes(x = total_reads, y = observed)) +\rgeom_point() +\rgeom_smooth(method=\u0026quot;lm\u0026quot;, se = FALSE) +\rlabs(x = \u0026quot;\\nTotal Reads\u0026quot;, y = \u0026quot;Observed Richness\\n\u0026quot;)\r\nWe see that the observed OTUs are correlated with the total read count (as expected). Now let’s subsample, plot, and test for group differences.\n#Subsample reads\r(ps_rare \u0026lt;- phyloseq::rarefy_even_depth(ps, rngseed = 123, replace = FALSE)) \r## `set.seed(123)` was used to initialize repeatable random subsampling.\r## Please record this for your records so others can reproduce.\r## Try `set.seed(123); .Random.seed` for the full vector\r## ...\r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 138 taxa and 84 samples ]\r## sample_data() Sample Data: [ 84 samples by 23 sample variables ]\r## tax_table() Taxonomy Table: [ 138 taxa by 7 taxonomic ranks ]\r## phy_tree() Phylogenetic Tree: [ 138 tips and 137 internal nodes ]\r## refseq() DNAStringSet: [ 138 reference sequences ]\rhead(phyloseq::sample_sums(ps_rare))\r## ERR1331793 ERR1331872 ERR1331819 ERR1331794 ERR1331851 ERR1331834 ## 5083 5083 5083 5083 5083 5083\r#Generate a data.frame with adiv measures\radiv \u0026lt;- data.frame(\r\u0026quot;Observed\u0026quot; = phyloseq::estimate_richness(ps_rare, measures = \u0026quot;Observed\u0026quot;),\r\u0026quot;Shannon\u0026quot; = phyloseq::estimate_richness(ps_rare, measures = \u0026quot;Shannon\u0026quot;),\r\u0026quot;PD\u0026quot; = picante::pd(samp = data.frame(t(data.frame(phyloseq::otu_table(ps_rare)))), tree = phyloseq::phy_tree(ps_rare))[, 1],\r\u0026quot;Status\u0026quot; = phyloseq::sample_data(ps_rare)$Status)\rhead(adiv)\r## Observed Shannon PD Status\r## ERR1331793 53 2.7462377 20.597980 Chronic Fatigue\r## ERR1331872 52 2.7527053 21.289719 Control\r## ERR1331819 70 3.2378006 21.671340 Control\r## ERR1331794 27 0.3761523 8.275154 Chronic Fatigue\r## ERR1331851 45 1.3387308 14.783592 Chronic Fatigue\r## ERR1331834 54 2.8883445 20.988640 Control\r#Plot adiv measures\radiv %\u0026gt;%\rgather(key = metric, value = value, c(\u0026quot;Observed\u0026quot;, \u0026quot;Shannon\u0026quot;, \u0026quot;PD\u0026quot;)) %\u0026gt;%\rmutate(metric = factor(metric, levels = c(\u0026quot;Observed\u0026quot;, \u0026quot;Shannon\u0026quot;, \u0026quot;PD\u0026quot;))) %\u0026gt;%\rggplot(aes(x = Status, y = value)) +\rgeom_boxplot(outlier.color = NA) +\rgeom_jitter(aes(color = Status), height = 0, width = .2) +\rlabs(x = \u0026quot;\u0026quot;, y = \u0026quot;\u0026quot;) +\rfacet_wrap(~ metric, scales = \u0026quot;free\u0026quot;) +\rtheme(legend.position=\u0026quot;none\u0026quot;)\r#Summarize\radiv %\u0026gt;%\rgroup_by(Status) %\u0026gt;%\rdplyr::summarise(median_observed = median(Observed),\rmedian_shannon = median(Shannon),\rmedian_pd = median(PD))\r## # A tibble: 2 x 4\r## Status median_observed median_shannon median_pd\r## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 Control 49 2.40 18.1\r## 2 Chronic Fatigue 46 2.30 17.0\r#Wilcoxon test of location\rwilcox.test(Observed ~ Status, data = adiv, exact = FALSE, conf.int = TRUE)\r## ## Wilcoxon rank sum test with continuity correction\r## ## data: Observed by Status\r## W = 1007.5, p-value = 0.2146\r## alternative hypothesis: true location shift is not equal to 0\r## 95 percent confidence interval:\r## -1.000059 5.000002\r## sample estimates:\r## difference in location ## 2.000087\rwilcox.test(Shannon ~ Status, data = adiv, conf.int = TRUE) \r## ## Wilcoxon rank sum test\r## ## data: Shannon by Status\r## W = 1037, p-value = 0.1329\r## alternative hypothesis: true location shift is not equal to 0\r## 95 percent confidence interval:\r## -0.04346366 0.39218192\r## sample estimates:\r## difference in location ## 0.1421467\rwilcox.test(PD ~ Status, data = adiv, conf.int = TRUE)\r## ## Wilcoxon rank sum test\r## ## data: PD by Status\r## W = 995, p-value = 0.2616\r## alternative hypothesis: true location shift is not equal to 0\r## 95 percent confidence interval:\r## -0.7452342 2.1356893\r## sample estimates:\r## difference in location ## 0.6854015\rHere we see a modestly lower median alpha-diversity in samples from participants with chronic fatigue when compared to healthy controls. However, the variation in alpha-diversity between groups is highly overlapping and we fail to reject the null hypothesis of no difference in location between groups.\n\nBelow is the code to estimate richness using breakaway. You will see some warnings. I plan to update this section with some additional data so check back soon.\n#Obtain breakaway estimates\rba_adiv \u0026lt;- breakaway::breakaway(ps)\rba_adiv[1]\r#Plot estimates\rplot(ba_adiv, ps, color = \u0026quot;Status\u0026quot;) #Examine models\rsummary(ba_adiv) %\u0026gt;%\radd_column(\u0026quot;SampleNames\u0026quot; = ps %\u0026gt;% otu_table %\u0026gt;% sample_names) #Test for group differnce\rbt \u0026lt;- breakaway::betta(summary(ba_adiv)$estimate,\rsummary(ba_adiv)$error,\rmake_design_matrix(ps, \u0026quot;Status\u0026quot;))\rbt$table \r\n\rBeta-diversity\rBeta-diversity provides a measure of similarity, or dissimilarity, of one microbial composition to another. Beta-diversity is typically calculated on the OTU/ASV/species composition tables directly (after normalization), but can be calculated using abundances at higher taxonomic levels. One common estimator of microbial beta-diversity is the pairwise Euclidean distance between samples. However, many ecologically informative measures are also commonly used and include:\n\rBray-Curtis similarity\rJaccard similarity\rYue \u0026amp; Clayton theta similarity\rUniFrac distance\rAND MANY MORE\r\rPat Schloss provides a listing and links to a large number of alpha- and beta-diversity estimators on his mothur wiki page. He also offers workshops on using mothur for processing amplicon sequence data and on using R for microbial ecologists a few times a year that I highly recommend.\nThis is probably a good time to touch on count normalization. One of the challenges we face working with NGS-derived sequence data is that the total number of reads for each sample is not directly tied to the starting quantity of DNA. You can think of the total reads (to a reasonable approximation) as getting assigned by a random sampling process where some samples just get doled out more reads. Thus, the total count does not carry any information on the absolute abundance of taxa. As long as the count is sufficiently large, it is just a factor that we want to account for in our analysis and is not of particular interest other than differences across samples can be a source of bias. Paul McMurdie provides an excellent discussion of the various goals and some approaches for normalization in his chapter on Normalization of Microbiome Profiling Data in the first edition of Microbiome Analysis. Weiss et. al. also provide a great introduction and examination of the impact of normalization approaches on beta-diversity ordinations and differential abundance testing.\nHere we will consider two approaches for library size normalization. The first will employ a compositional data analysis approach and involves working with log-ratios. The second will involve simply subsampling the data without replacement; however, this approach comes with limiations. We will use it here as the authors of the UniFrac method have suggested that rarefying more clearly clusters samples according to biological origin than other normalization techniques do for ordination metrics based on presence or absence (i.e. unweighted UniFrac).\nA detailed discussion of compositional data analysis (CoDA) is beyond the scope of this session. I plan to add a tutorial devoted to CoDA in the future so check back. At a high-level compositional data (i.e. data that carry only relative information and are constrained by a unit sum) exist in a restricted subspace of the Euclidian geometry referred to as the D-1 simplex (I know this doesn’t feel high-level). Due to this constraint, these data fail to meet many of the assumptions of our favorite statistical methods developed for unconstrained random variables. Working with ratios of compositional elements lets us transform these data to the Euclidian space and apply our favorite methods (so we don’t need to work in the simplex). Working with their logarithms makes them easier to interpret. There are different types of log-ratio “transformations” including the additive log-ratio, centered log-ratio, and isometric log-ratio transforms. Below are some great resources for learning more about compositional data analysis:\n*Understanding sequencing data as compositions: an outlook and review by Quinn et. al. in Bioinformatics (2018)\n*Statistical Analysis of Microbiome Data with R - Ch. 10\n*Applied Compositional Data Analysis by Filzmoser, Hron, and Templ (2018)\n*Analyzing Compositional Data with R by Boogaart and Tolosana-Delgado (2013)\n\nBelow we generate a beta-diversity ordination using the Aitchison distance. This is simply applying PCA to the centered log-ratio (CLR) transformed counts. We will use the microbiome package to do this and assign a pseudocount of 1 to facilitate the transformation (since the log of zero is undefined). There are alternative/better approaches than using a pseudocount and we will examine one in the next section. First we perform the transformation.\n#CLR transform\r(ps_clr \u0026lt;- microbiome::transform(ps, \u0026quot;clr\u0026quot;)) \r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 138 taxa and 84 samples ]\r## sample_data() Sample Data: [ 84 samples by 23 sample variables ]\r## tax_table() Taxonomy Table: [ 138 taxa by 7 taxonomic ranks ]\r## phy_tree() Phylogenetic Tree: [ 138 tips and 137 internal nodes ]\r## refseq() DNAStringSet: [ 138 reference sequences ]\rphyloseq::otu_table(ps)[1:5, 1:5]\r## OTU Table: [5 taxa and 5 samples]\r## taxa are rows\r## ERR1331793 ERR1331872 ERR1331819 ERR1331794 ERR1331851\r## OTU1 2 581 347 916 10498\r## OTU2 371 46 0 233 301\r## OTU3 1189 81 637 199 0\r## OTU4 0 172 246 0 372\r## OTU5 308 44 143 155 221\rphyloseq::otu_table(ps_clr)[1:5, 1:5]\r## OTU Table: [5 taxa and 5 samples]\r## taxa are rows\r## ERR1331793 ERR1331872 ERR1331819 ERR1331794 ERR1331851\r## OTU1 1.289544 5.812706 5.615063 6.230204 9.467837\r## OTU2 6.485240 3.280355 -3.079591 4.863001 5.916398\r## OTU3 7.649802 3.844401 6.222432 4.705673 -1.903003\r## OTU4 -2.317399 4.596219 5.271139 -1.178342 6.128105\r## OTU5 6.299168 3.236089 4.728822 4.456584 5.607596\rWe can see that the values are now no longer counts, but rather the dominance (or lack thereof) for each taxa relative to the geometric mean of all taxa on the logarithmic scale (any log base could be used and often log2 or log10 may aid in interpretation).\n\nNow we will conduct the PCA, examine the relative importance of each principal component, and generate the ordination. PCA is an unsupervised learning approach that can help us see similarities between samples when there are a large number of features. Scatter plots are not much help here in high-dimensions since the number of possible plots is equal to p(p-1)2 where p = the number of features (quickly becomes intractable). So we need to find an approach that will let us map these data to a lower-dimensional space. This is what PCA does. It identifies latent variables referred to as principal components (PC) that capture as much of the information as possible…where information is the amount of variation in the data. We can then focus on those PCs that are most interesting (i.e. explain the most variation; give us the best lower-dimensional mapping). Given we can only visualize our samples in 2- or 3-dimenstional space, most microbiome studies only plot the data using either the first couple of PCs. A more though introduction to PCA can be found in the textbook An Introduction to Statistical Learning by James, Witten, Hastie, and Tibshirani (2013). Let’s give it a try!\n#PCA via phyloseq\rord_clr \u0026lt;- phyloseq::ordinate(ps_clr, \u0026quot;RDA\u0026quot;)\r#Plot scree plot\rphyloseq::plot_scree(ord_clr) + geom_bar(stat=\u0026quot;identity\u0026quot;, fill = \u0026quot;blue\u0026quot;) +\rlabs(x = \u0026quot;\\nAxis\u0026quot;, y = \u0026quot;Proportion of Variance\\n\u0026quot;)\r#Examine eigenvalues and % prop. variance explained\rhead(ord_clr$CA$eig) \r## PC1 PC2 PC3 PC4 PC5 PC6 ## 75.69204 36.27003 33.16649 29.08833 25.52986 24.32215\rsapply(ord_clr$CA$eig[1:5], function(x) x / sum(ord_clr$CA$eig)) \r## PC1 PC2 PC3 PC4 PC5 ## 0.10744095 0.05148344 0.04707812 0.04128939 0.03623832\rRDA without constraints is PCA…and we can generate the PCs using the phyloseq::ordinate function. A scree plot is then used to examine the proportion of total variation explained by each PC. Here we see that the first PC really stands out and then we have a gradual decline for the remaining components. You may hear people talk about looking for the “elbow” in the plot where the information plateaus to select the number of PCs to retain. Below we plot the first two components and scale the plot to reflect the relative amount of information explained by each axis as recommended by Nguyen and Holmes in their paper Ten quick tips for effective dimensionality reduction.\n\n#Scale axes and plot ordination\rclr1 \u0026lt;- ord_clr$CA$eig[1] / sum(ord_clr$CA$eig)\rclr2 \u0026lt;- ord_clr$CA$eig[2] / sum(ord_clr$CA$eig)\rphyloseq::plot_ordination(ps, ord_clr, type=\u0026quot;samples\u0026quot;, color=\u0026quot;Status\u0026quot;) + geom_point(size = 2) +\rcoord_fixed(clr2 / clr1) +\rstat_ellipse(aes(group = Status), linetype = 2)\rWe see some separation between the chronic fatigue and healthy controls samples suggesting some differences in the communities according to sample type. There is also a fair degree of overlap as is often seen in clinical research studies examining the same environment in two different patient populations. While PCA is an exploratory data visualization tool, we can test whether the samples cluster beyond that expected by sampling variability using permutational multivariate analysis of variance (PERMANOVA). It does this by partitioning the sums of squares for the within- and between-cluster components using the concept of centroids. Many permutations of the data (i.e. random shuffling) are used to generate the null distribution. The test from ADONIS can be confounded by differences in dispersion (or spread)…so we want to check this as well.\r#Generate distance matrix\rclr_dist_matrix \u0026lt;- phyloseq::distance(ps_clr, method = \u0026quot;euclidean\u0026quot;) #ADONIS test\rvegan::adonis(clr_dist_matrix ~ phyloseq::sample_data(ps_clr)$Status)\r## ## Call:\r## vegan::adonis(formula = clr_dist_matrix ~ phyloseq::sample_data(ps_clr)$Status) ## ## Permutation: free\r## Number of permutations: 999\r## ## Terms added sequentially (first to last)\r## ## Df SumsOfSqs MeanSqs F.Model R2\r## phyloseq::sample_data(ps_clr)$Status 1 2240 2240.17 3.2666 0.03831\r## Residuals 82 56233 685.77 0.96169\r## Total 83 58473 1.00000\r## Pr(\u0026gt;F) ## phyloseq::sample_data(ps_clr)$Status 0.001 ***\r## Residuals ## Total ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r#Dispersion test and plot\rdispr \u0026lt;- vegan::betadisper(clr_dist_matrix, phyloseq::sample_data(ps_clr)$Status)\rdispr\r## ## Homogeneity of multivariate dispersions\r## ## Call: vegan::betadisper(d = clr_dist_matrix, group =\r## phyloseq::sample_data(ps_clr)$Status)\r## ## No. of Positive Eigenvalues: 83\r## No. of Negative Eigenvalues: 0\r## ## Average distance to median:\r## Control Chronic Fatigue ## 25.1 26.2 ## ## Eigenvalues for PCoA axes:\r## (Showing 8 of 83 eigenvalues)\r## PCoA1 PCoA2 PCoA3 PCoA4 PCoA5 PCoA6 PCoA7 PCoA8 ## 6282 3010 2753 2414 2119 2019 1895 1693\rplot(dispr, main = \u0026quot;Ordination Centroids and Dispersion Labeled: Aitchison Distance\u0026quot;, sub = \u0026quot;\u0026quot;)\rboxplot(dispr, main = \u0026quot;\u0026quot;, xlab = \u0026quot;\u0026quot;)\rpermutest(dispr)\r## ## Permutation test for homogeneity of multivariate dispersions\r## Permutation: free\r## Number of permutations: 999\r## ## Response: Distances\r## Df Sum Sq Mean Sq F N.Perm Pr(\u0026gt;F) ## Groups 1 24.95 24.9463 3.0491 999 0.075 .\r## Residuals 82 670.89 8.1816 ## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\rWe reject the null hypothesis of no difference in the centroid location according to Status. However, the proportion of variance explained is quite small. You might get slightly different numbers. This is because of the random process generating the permutations. There is a suggestion that the dispersion is greater in samples from patients with chronic fatigue syndrome. However, it does not exceed that expected by sampling variablilty at this sample size.\rAs has been explained by others (Xia, Sun, and Chen; Ch 7.4), I want to mention that this type of testing is akin to attempting to “explain” the axes using metadata fields. A more formal approach to hypotheses testing can be done using redundancy analysis or canonical correspondence analysis that directly uses information on metadata fields when generating the ordinations and conducting testing. These approaches directly test hypotheses about environmental variables. I will not demonstrate these approaches here, but they can be computed using some of these same commands with minor modifications.\nLastly, I want to show you how you can bring in information the form of a phylogenic tree into beta-diversity analysis. The UniFrac metric incorporates phylogenic information by calculating the total branch lengths “unshared” between two samples divided by the total branch length. This approach often reveals interesting differences in the phylogenic relatedness between samples and sample types. Here we compute the weighted and unweighted UniFrac metrics using PCoA. PCoA can be thought of as PCA for non-Euclidian measures.\n#Generate distances\rord_unifrac \u0026lt;- ordinate(ps_rare, method = \u0026quot;PCoA\u0026quot;, distance = \u0026quot;wunifrac\u0026quot;) ord_unifrac_un \u0026lt;- ordinate(ps_rare, method = \u0026quot;PCoA\u0026quot;, distance = \u0026quot;unifrac\u0026quot;) #Plot ordinations\ra \u0026lt;- plot_ordination(ps_rare, ord_unifrac, color = \u0026quot;Status\u0026quot;) + geom_point(size = 2)\rb \u0026lt;- plot_ordination(ps_rare, ord_unifrac_un, color = \u0026quot;Status\u0026quot;) + geom_point(size = 2)\rcowplot::plot_grid(a, b, nrow = 1, ncol = 2, scale = .9, labels = c(\u0026quot;Weighted\u0026quot;, \u0026quot;Unweighted\u0026quot;))\rThere is a large amount of overlap between sample types for the weighted UniFrac distance (accounts for the relative abundance of each of the taxa within the communities). However, there is clustering on at least the first axis for the unweighted UniFrac distance that is not “explained” by Status. Is there a metadata field in the data that reflects this separation? I’ll let you explore on your own.\n\n\rDifferential abundance testing\rThe goal of differential abundance testing is to identify specific taxa associated with clinical metadata variables of interest. This is a difficult task. It is also one of the more controversial areas in microbiome data analysis. Some of the reasons for this are described in a recent paper by James Morton et. al. in Nature Communications (2019), but is related to concerns that normalization and testing approaches have generally failed to control false discovery rates (here is a good example) and this has contributed to the lack of reproducibility in microbiome studies. If you think about it for a moment, a couple of difficulties come to mind:\n\rThe goal of this type of analysis is to identify taxa that differ the most between conditions (or along a continuous gradient). Basically, we are identifying the most extreme results in the data. We would therefore expect some/many/most of these findings to have been “outlying” results simply due to chance sampling variation and to perhaps regress back towards the mean/null value when tested in a new sample of patients.\rThe data are compositional and thus changes in one or more taxa can make it look like other/all taxa are changing. James Morton has an excellent example of this here. Methods that don’t properly account of the compositional nature of the data can have very high false discovery rates..\rFunctionally redundant taxa may serve the same “niche” in different environments or populations causing different taxa to be identified as differentially abundant across samples (however the testing approach would not be what is misleading here).\rThe high correlation between many taxa may cause different, but highly correlated, features to be selected in different studies.\r\rProfessor Frank Harrell provides a great overview of this general concern in Chapter 20 of his Biostatistics for Biomedical Research online text. For general thoughts on statistics and predictive modeling I highly recommend that you check out his blog and regression modeling strategies course notes.\nOther fields have wrestled with similar problems and have introduced approaches such as the requirement of replicating results in multiple cohorts of patients prior to publication (or at least employing rigorous resampling approaches to gauge the reproducibility), analysis pre-specification, and focusing more on prediction than “naming names”. For compositional data including external information in the form of external spike-ins or estimates of total abundance (such as estimating total microbial load using qPCR), working with ratios, limiting the emphasis on testing, and understanding the limits of compositional data are likely reasonable ways forward here. However, none of these are a panacea. Methodologists working in the area of microbiome data analysis are addressing some of these issues, but there is still much work to be done. Two excellent recent papers you should check out include James Morton’s paper above and this preprint in biorxiv by McLaren, Willis and Callahan (2019) explaining and modeling correctable bias in metagenomic sequence studies.\nIn this section, I will present a two approaches for estimating differential abundance. The first is simply applying the non-parametric Wilcoxon rank-sum test to each taxon. The second is a version of the Wilcoxon test developed for compositional NGS data. I chose these two approaches since they are commonly used in microbiome studies and I expect many of you will have some familiarity with the Wilcoxon test or (Gosset’s) t-test. However, all results should be interpreted in light of the concerns raised above. I also include the use of a CoDA transform for both since there does seem to be some growing support that log-ratio methodologies may better control the false positive rate.\nMany researchers will apply the non-parametric Wilcoxon rank-sum test to each OTU/ASV/species after normalization. We will do this here. We will also use nested data frames as advocated by Hadley Wickham to keep the data and test results together in a single data.frame. At first, I found this approach a little strange. However, I have come to use it all the time. It is perhaps a bit overkill here, but a very helpful framework when you want to run many models and then save them together with the data and results (especially when they take a long time to run). Here is a link to a complete description of the nested frame approach in the R for Data Science book. We also use the map function from purr. This operates like a for loop, allowing us to iterate the test over each OTU, but with less coding. This is a big chunk of code. I will talk you through it.\n#Generate data.frame with OTUs and metadata\rps_wilcox \u0026lt;- data.frame(t(data.frame(phyloseq::otu_table(ps_clr))))\rps_wilcox$Status \u0026lt;- phyloseq::sample_data(ps_clr)$Status\r#Define functions to pass to map\rwilcox_model \u0026lt;- function(df){\rwilcox.test(abund ~ Status, data = df)\r}\rwilcox_pval \u0026lt;- function(df){\rwilcox.test(abund ~ Status, data = df)$p.value\r}\r#Create nested data frames by OTU and loop over each using map wilcox_results \u0026lt;- ps_wilcox %\u0026gt;%\rgather(key = OTU, value = abund, -Status) %\u0026gt;%\rgroup_by(OTU) %\u0026gt;%\rnest() %\u0026gt;%\rmutate(wilcox_test = map(data, wilcox_model),\rp_value = map(data, wilcox_pval)) #Show results\rhead(wilcox_results)\r## # A tibble: 6 x 4\r## OTU data wilcox_test p_value ## \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; ## 1 OTU1 \u0026lt;tibble [84 x 2]\u0026gt; \u0026lt;S3: htest\u0026gt; \u0026lt;dbl [1]\u0026gt;\r## 2 OTU2 \u0026lt;tibble [84 x 2]\u0026gt; \u0026lt;S3: htest\u0026gt; \u0026lt;dbl [1]\u0026gt;\r## 3 OTU3 \u0026lt;tibble [84 x 2]\u0026gt; \u0026lt;S3: htest\u0026gt; \u0026lt;dbl [1]\u0026gt;\r## 4 OTU4 \u0026lt;tibble [84 x 2]\u0026gt; \u0026lt;S3: htest\u0026gt; \u0026lt;dbl [1]\u0026gt;\r## 5 OTU5 \u0026lt;tibble [84 x 2]\u0026gt; \u0026lt;S3: htest\u0026gt; \u0026lt;dbl [1]\u0026gt;\r## 6 OTU6 \u0026lt;tibble [84 x 2]\u0026gt; \u0026lt;S3: htest\u0026gt; \u0026lt;dbl [1]\u0026gt;\rhead(wilcox_results$data[[1]])\r## # A tibble: 6 x 2\r## Status abund\r## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 Chronic Fatigue 1.29\r## 2 Control 5.81\r## 3 Control 5.62\r## 4 Chronic Fatigue 6.23\r## 5 Chronic Fatigue 9.47\r## 6 Control 7.43\rwilcox_results$wilcox_test[[1]]\r## ## Wilcoxon rank sum test\r## ## data: abund by Status\r## W = 1172, p-value = 0.006066\r## alternative hypothesis: true location shift is not equal to 0\rwilcox_results$p_value[[1]]\r## [1] 0.006066387\rHere we can see that we have a tibble where:\n\reach OTU is a row\rthe data column contains a tibble for each OTU that contains the CLR abundance and Status fields (i.e. seperate data.frame for each OTU)\rthe wilcox_test column contains the results of each Wilcoxon test\rthe p_value column contains the extracted p-value for each test\r\r\nNow we will unnest the results, grab the OTU names and p-values, add the taxonomic labels, and calculate the FDR adjusted p-values.\n#Unnesting\rwilcox_results \u0026lt;- wilcox_results %\u0026gt;%\rdplyr::select(OTU, p_value) %\u0026gt;%\runnest()\rhead(wilcox_results)\r## # A tibble: 6 x 2\r## OTU p_value\r## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 OTU1 0.00607\r## 2 OTU2 0.0686 ## 3 OTU3 0.830 ## 4 OTU4 0.0130 ## 5 OTU5 0.419 ## 6 OTU6 0.258\r#Adding taxonomic labels\rtaxa_info \u0026lt;- data.frame(tax_table(ps_clr))\rtaxa_info \u0026lt;- taxa_info %\u0026gt;% rownames_to_column(var = \u0026quot;OTU\u0026quot;)\r#Computing FDR corrected p-values\rwilcox_results \u0026lt;- wilcox_results %\u0026gt;%\rfull_join(taxa_info) %\u0026gt;%\rarrange(p_value) %\u0026gt;%\rmutate(BH_FDR = p.adjust(p_value, \u0026quot;BH\u0026quot;)) %\u0026gt;%\rfilter(BH_FDR \u0026lt; 0.05) %\u0026gt;%\rdplyr::select(OTU, p_value, BH_FDR, everything())\r## Joining, by = \u0026quot;OTU\u0026quot;\r#Printing results\rprint.data.frame(wilcox_results) \r## OTU p_value BH_FDR Kingdom Phylum Class\r## 1 OTU48 1.893126e-05 0.002612514 Bacteria Firmicutes Clostridia\r## 2 OTU38 4.168412e-05 0.002876205 Bacteria Firmicutes Clostridia\r## 3 OTU44 2.750125e-04 0.012650574 Bacteria Firmicutes Clostridia\r## 4 OTU61 1.217944e-03 0.038379997 Bacteria Firmicutes Clostridia\r## 5 OTU104 1.390580e-03 0.038379997 Bacteria Firmicutes Clostridia\r## 6 OTU115 1.804359e-03 0.040427044 Bacteria Firmicutes Clostridia\r## 7 OTU83 2.050647e-03 0.040427044 Bacteria Firmicutes Clostridia\r## 8 OTU8 2.719699e-03 0.041702048 Bacteria Firmicutes Clostridia\r## 9 OTU123 2.719699e-03 0.041702048 Bacteria Firmicutes Erysipelotrichi\r## Order Family Genus Species\r## 1 Clostridiales Lachnospiraceae Coprococcus \u0026lt;NA\u0026gt;\r## 2 Clostridiales Ruminococcaceae Oscillospira \u0026lt;NA\u0026gt;\r## 3 Clostridiales Lachnospiraceae [Ruminococcus] \u0026lt;NA\u0026gt;\r## 4 Clostridiales Lachnospiraceae \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt;\r## 5 Clostridiales Lachnospiraceae Blautia producta\r## 6 Clostridiales [Mogibacteriaceae] \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt;\r## 7 Clostridiales Lachnospiraceae Blautia \u0026lt;NA\u0026gt;\r## 8 Clostridiales Lachnospiraceae [Ruminococcus] \u0026lt;NA\u0026gt;\r## 9 Erysipelotrichales Erysipelotrichaceae Coprobacillus \u0026lt;NA\u0026gt;\rHere we see that we have several Clostridiales organisms identified as differentially abundant. Next, we might use bootstrap resampling to see how often these results replicated in subsets of the data and calculate a measure of effect size. However, we will not do that here. Instead we will take a look at another approach that uses the Wilcoxon test on the CLR transformed data with some improvements in the treatment of zero values and presentation of effect size.\n\nANOVA-like differential expression (ALDEx2) is a popular CoDA method for differential abundance testing. ALDEx2 can be run via a single command; however, there are several steps that are occurring in the background. At a high-level, the steps include:\n\rGenerate a large number (here n=128) of posterior probabilities for the observance of each taxon (i.e. output many data.frames where the counts have been converted to proportions). This is done by Monte-Carlo sampling from a Dirichlet distribution with a small non-zero prior to deal with zeros. The total read count therefore only contributes to the precision of the proportions.\rApply the centered log-ratio transformation to each instance.\rApply the Wilcoxon test to each taxon for each simulated instance.\rEstimate the effect size as the difference between conditions divided by the maximum difference within conditions averaging over all instances. Scaling the between group difference by the maximum within group difference gives us a standardized effect size measure.\rObtain the expected p-values for each taxon by averaging over all instances.\rApply the BH-FDR correction to control the false positive rate.\r\rFor a more through explanation see the ALDEx2 Bioconductor vignette.\nLets give it a try.\n#Run ALDEx2\raldex2_da \u0026lt;- ALDEx2::aldex(data.frame(phyloseq::otu_table(ps)), phyloseq::sample_data(ps)$Status, test=\u0026quot;t\u0026quot;, effect = TRUE, denom=\u0026quot;iqlr\u0026quot;)\r## aldex.clr: generating Monte-Carlo instances and clr values\r## operating in serial mode\r## computing iqlr centering\r## aldex.ttest: doing t-test\r## aldex.effect: calculating effect sizes\r#Plot effect sizes\rALDEx2::aldex.plot(aldex2_da, type=\u0026quot;MW\u0026quot;, test=\u0026quot;wilcox\u0026quot;, called.cex = 1, cutoff = 0.05)\rThe output highlights the various steps for the ALDEx2 workflow. The interquartile log-ratio (iqlr) centering uses as the basis for the CLR transform the set of features that have variance values that fall between the first and third quartiles for all features in all groups in the dataset. This provides results that are more robust to asymmetric features between groups.\nThe effect size plot shows the median log2 fold difference by the median log2 dispersion. This is a measure of the effect size by the variability. Differentially abundant taxon will be those where the difference most exceeds the dispersion. Points toward the top of the figure are more abundant in CF samples while those towards the bottom are more abundant in healthy controls. Taxa with BH-FDR corrected p-values are shown in red. However, the authors state that:\n\rWe prefer to use the effect size whenever possible rather than statistical significance since an effect size tells the scientist what they want to know—“what is reproducibly different between groups”; this is emphatically not something that P values deliver.\rNow we will print the output with the taxonomic classifications appended. WE use the FDR p-values here to facilitate the comparison with the results from Wilcoxon test ran outside of ALDEx2.\n\r#Clean up presentation\rsig_aldex2 \u0026lt;- aldex2_da %\u0026gt;%\rrownames_to_column(var = \u0026quot;OTU\u0026quot;) %\u0026gt;%\rfilter(wi.eBH \u0026lt; 0.05) %\u0026gt;%\rarrange(effect, wi.eBH) %\u0026gt;%\rdplyr::select(OTU, diff.btw, diff.win, effect, wi.ep, wi.eBH)\rsig_aldex2 \u0026lt;- left_join(sig_aldex2, taxa_info)\r## Joining, by = \u0026quot;OTU\u0026quot;\rsig_aldex2\r## OTU diff.btw diff.win effect wi.ep wi.eBH Kingdom\r## 1 OTU8 -2.307035 5.522587 -0.3839105 0.0015096450 0.039837292 Bacteria\r## 2 OTU48 3.639216 6.528139 0.5283635 0.0025403967 0.042007768 Bacteria\r## 3 OTU44 3.541267 6.324375 0.5296702 0.0013725146 0.031600961 Bacteria\r## 4 OTU38 3.277257 4.696329 0.6206553 0.0000348666 0.004124241 Bacteria\r## Phylum Class Order Family Genus\r## 1 Firmicutes Clostridia Clostridiales Lachnospiraceae [Ruminococcus]\r## 2 Firmicutes Clostridia Clostridiales Lachnospiraceae Coprococcus\r## 3 Firmicutes Clostridia Clostridiales Lachnospiraceae [Ruminococcus]\r## 4 Firmicutes Clostridia Clostridiales Ruminococcaceae Oscillospira\r## Species\r## 1 \u0026lt;NA\u0026gt;\r## 2 \u0026lt;NA\u0026gt;\r## 3 \u0026lt;NA\u0026gt;\r## 4 \u0026lt;NA\u0026gt;\rHere we see that again that several Clostridiales organisms are identified as differentially abundant. Consistent with the results of running the Wilcoxon test outside of ALDEx2, we see that OTU48, OTU38, OTU44, and OTU8 are listed as differentially abundant. The others do not reach the FDR cut-off used here; although, they likely have “largish” effect sizes. Try and see if you can obtain these values. The reason for the discrepancy is hard to discern, but may be related to differences in the use of the CLR basis (geometric mean of all taxa versus the IQLR) and/or the use of the Bayesian resampling with a non-zero prior.\nOften, if I consider performing DA testing, I will run several models and focus on the intersection of OTUs and try to gain some insight into how the different normalization and/or models many be influencing the results.\nThere are MANY other approaches that can be used to attempt to identify differently abundant taxa. Some that are popular, or that I find interesting, and can be implemented in R include:\n\rCount Regression for Correlated Observations with the Beta-binomial (corncob)\rMicrobiomeDDA\rDESeq2\rAnalysis of Composition of Microbiomes (ANCOM)\r\rOutside of R, a recently developed approach using multinomial regression via tensorflow and differential ranking looks promising.\n\n\rPrediction\rAs discussed by Dr. Haslam in the first lecture, the majority of clinical microbiome studies, conducted to date, have been correlative or focused on predicting outcomes using taxonomic abundances as the feature set. The predictive utility of the human microbiome in health and disease is of great interest and numerous studies have reported the ability to predict outcomes from metagenomic data. For example, here are links to three studies suggesting taxonomic profiles in fecal samples may predict the occurrence of colorectal cancer (1, 2, 3).\nAs with differential abundance testing, there are many models or statistical learning approaches that can be applied to metagenomic data for the purpose of predicting an outcome. For binary outcomes, generating predicted probabilities for the outcome of interest using generalized linear models (GLMs) is one approach. Machine learning approaches have also been used extensively in microbiome research; however, these approaches may likely require much larger datasets than they have typically been trained on if our goal is reproducible results (the same likely goes for most studies using GLMs, etc.).\nOne challenge we face when building a predictive model from metagenomic data is that we often have more features (taxon) than we have samples. For example, if we are working with microbial strains we might have more than 10,000 features to consider. One way to define high-dimensional data is when p \u0026gt; n, where: p = number of features and n = the number of samples. In these instances, one approach forward to reduce the dimensionality of the data. We did this earlier when we used PCA to extract the first two PCs that explained the largest fraction of variably in our data. Using a subset of the PCs as predictors in a GLM is known as principal components regression. We will give this approach a try below. Another is to include all the features as predictors, but to shrink their effects towards zero (or sometimes shrink them entirely out of the model). These approaches go by names such as ridge regression, LASSO, elastic nets, etc. Bayesian models with skeptical priors also can work well here. We will use a form of penalization on the principal components regression model below to highlight this approach and address potential overfitting even with just three PCs at this sample size (which is likely too small for robust prediction). A helpful guide to think about how many features or samples one might require to develop a predictive model is to consider how much overfitting you are willing to accept. Here are links to two excellent papers describing sample size determinations for continuous and binary outcomes in predictive modeling.\nWe will also examine a CoDA greedy stepwise selection model using balances that I think is a lot of fun…and very user-friendly.\nFor those interested in general resources for prediction modeling I recommend:\n\rFrank Harrell’s Regression Modeling Stratagies website and textbook\rEwout Steyerberg’s Clinical Prediction Models textbook for a bit more introductory text\rMax Kuhn’s Applied Predictive Modeling textbook\rJames, Witten, Hastie, and Tibshirani’s An Introduction to Statistical Learning\r\rFirst we will create a data.frame that contains the Status and the first 3 PCs from the centered-log ratio transformed abundance table we generated before. We will then plot the unconditional association for each PC with the outcome of CF versus control.\n#Generate data.frame\rclr_pcs \u0026lt;- data.frame(\r\u0026quot;pc1\u0026quot; = ord_clr$CA$u[,1],\r\u0026quot;pc2\u0026quot; = ord_clr$CA$u[,2],\r\u0026quot;pc3\u0026quot; = ord_clr$CA$u[,3],\r\u0026quot;Status\u0026quot; = phyloseq::sample_data(ps_clr)$Status\r)\rclr_pcs$Status_num \u0026lt;- ifelse(clr_pcs$Status == \u0026quot;Control\u0026quot;, 0, 1)\rhead(clr_pcs)\r## pc1 pc2 pc3 Status\r## ERR1331793 0.02850343 -0.07709724 0.0938970408 Chronic Fatigue\r## ERR1331872 -0.08156129 0.14193568 0.1155088427 Control\r## ERR1331819 -0.19356039 -0.08436341 -0.1048722096 Control\r## ERR1331794 -0.04193714 0.09705602 0.0110912849 Chronic Fatigue\r## ERR1331851 0.09994410 0.05534786 -0.0005008101 Chronic Fatigue\r## ERR1331834 -0.15577774 0.02921040 -0.0204667015 Control\r## Status_num\r## ERR1331793 1\r## ERR1331872 0\r## ERR1331819 0\r## ERR1331794 1\r## ERR1331851 1\r## ERR1331834 0\r#Specify a datadist object (for rms)\rdd \u0026lt;- datadist(clr_pcs)\roptions(datadist = \u0026quot;dd\u0026quot;)\r#Plot the unconditional associations\ra \u0026lt;- ggplot(clr_pcs, aes(x = pc1, y = Status_num)) +\rHmisc::histSpikeg(Status_num ~ pc1, lowess = TRUE, data = clr_pcs) +\rlabs(x = \u0026quot;\\nPC1\u0026quot;, y = \u0026quot;Pr(Chronic Fatigue)\\n\u0026quot;)\rb \u0026lt;- ggplot(clr_pcs, aes(x = pc2, y = Status_num)) +\rHmisc::histSpikeg(Status_num ~ pc2, lowess = TRUE, data = clr_pcs) +\rlabs(x = \u0026quot;\\nPC2\u0026quot;, y = \u0026quot;Pr(Chronic Fatigue)\\n\u0026quot;)\rc \u0026lt;- ggplot(clr_pcs, aes(x = pc3, y = Status_num)) +\rHmisc::histSpikeg(Status_num ~ pc3, lowess = TRUE, data = clr_pcs) +\rlabs(x = \u0026quot;\\nPC3\u0026quot;, y = \u0026quot;Pr(Chronic Fatigue)\\n\u0026quot;)\rcowplot::plot_grid(a, b, c, nrow = 2, ncol = 2, scale = .9, labels = \u0026quot;AUTO\u0026quot;)\rWe see that we have the potential for some non-linear associations. Professor Harrell recommends that it is generally a good idea to assume some level of complexity since the penalty for allowing for a non-linear fit, when the association is in fact linear, is much less than when assuming linearity when the association is non-linear (i.e. you fit a straight line through a u-shaped curve). His rms package, along with the tidyverse, are the two packages I use most often and allows us to model this type of complexity easily using restricted cubic splines. These are a set of highly flexible, smoothly joined, piecewise polynomials entered for each variable. The number and placement of the knots helps control the flexibility. We will allow three knots for each term. However, this results in an additional 3 (6 total) model degrees of freedom…but we will shrink this down.\nWe first fit the full model and then perform a grid search to identify the optimum value for the penalty. We can also allow the penalty to differ for the simple and complex (i.e. nonlinear or interactions) terms. This is helpful if we want to allow for complexity, but down weight its impact. This would kind of be like adding more restrictive priors to the non-linear terms in a Bayesian model. We then plot the penalized log odds.\n#Fit full model with splines (3 knots each)\rm1 \u0026lt;- rms::lrm(Status_num ~ rcs(pc1, 3) + rcs(pc2, 3) + rcs(pc3, 3), data = clr_pcs, x = TRUE, y = TRUE)\r#Grid search for penalties\rpentrace(m1, list(simple = c(0, 1, 2), nonlinear = c(0, 100, 200)))\r## ## Best penalty:\r## ## simple nonlinear df\r## 1 200 2.783027\r## ## simple nonlinear df aic bic aic.c\r## 0 0 6.000000 23.10845 8.523552 22.01754\r## 0 100 3.049209 28.21043 20.798359 27.90157\r## 1 100 2.810152 28.38363 21.552668 28.11659\r## 2 100 2.641219 28.11811 21.697792 27.87875\r## 0 200 3.024831 28.24577 20.892958 27.94131\r## 1 200 2.783027 28.42060 21.655570 28.15810\r## 2 200 2.611196 28.15166 21.804324 27.91706\rpen_m1 \u0026lt;- update(m1, penalty = list(simple = 1, nonlinear = 200))\rpen_m1\r## Logistic Regression Model\r## ## rms::lrm(formula = Status_num ~ rcs(pc1, 3) + rcs(pc2, 3) + rcs(pc3, ## 3), data = clr_pcs, x = TRUE, y = TRUE, penalty = list(simple = 1, ## nonlinear = 200))\r## ## ## Penalty factors\r## ## simple nonlinear interaction nonlinear.interaction\r## 1 200 200 200\r## ## Model Likelihood Discrimination Rank Discrim. ## Ratio Test Indexes Indexes ## Obs 84 LR chi2 33.99 R2 0.421 C 0.848 ## 0 37 d.f. 2.783 g 1.759 Dxy 0.695 ## 1 47 Pr(\u0026gt; chi2)\u0026lt;0.0001 gr 5.807 gamma 0.695 ## max |deriv| 1e-12 Penalty 2.34 gp 0.322 tau-a 0.347 ## Brier 0.159 ## ## Coef S.E. Wald Z Pr(\u0026gt;|Z|) Penalty Scale\r## Intercept 0.3458 0.2852 1.21 0.2254 0.0000 ## pc1 11.6489 2.8714 4.06 \u0026lt;0.0001 0.1098 ## pc1\u0026#39; 0.1202 0.9287 0.13 0.8970 1.0715 ## pc2 6.4946 2.5132 2.58 0.0098 0.1098 ## pc2\u0026#39; -0.0015 0.7643 0.00 0.9984 1.2987 ## pc3 -3.8538 2.5659 -1.50 0.1331 0.1098 ## pc3\u0026#39; 0.0259 1.0080 0.03 0.9795 0.9856 ## \r#Plot log odds\rggplot(Predict(pen_m1))\rWe can see from the value of the penalties and the resultant log odds that the conditional associations are quite linear. However, we will leave in the cubic spline terms to fully account for the degrees of freedom we entertained in the model building process. The optimal penalties were 1 for the simple and 200 for the non-linear terms (higher is better for the corrected AIC) and the effective degrees of freedom shrunk to 2.78. We won’t interpret the coefficients here since we purposefully biased them towards zero.\nThe Brier score is 0.16 and provides a measure of the mean squared difference between the predicted probabilities and actual outcomes. Thus, it is a quadratic proper scoring rule. The c-statistic is analogous to the area under the receiver operating characteristic curve and is a measure of rank discrimination. Here it is c = 0.85.\n\nNo we will perform bootstrap resampling to obtain an out-of-sample estimate of model performance. Here is a link describing this in greater detail.\n#Obtain optimism corrected estimates\r(val \u0026lt;- rms::validate(pen_m1))\r## index.orig training test optimism index.corrected n\r## Dxy 0.6952 0.7248 0.6817 0.0431 0.6521 40\r## R2 0.4206 0.4536 0.4295 0.0240 0.3965 40\r## Intercept 0.0000 0.0000 -0.0250 0.0250 -0.0250 40\r## Slope 1.0000 1.0000 1.0265 -0.0265 1.0265 40\r## Emax 0.0000 0.0000 0.0100 0.0100 0.0100 40\r## D 0.3927 0.4045 0.3749 0.0297 0.3630 40\r## U -0.0238 -0.0238 -0.0073 -0.0165 -0.0073 40\r## Q 0.4165 0.4283 0.3822 0.0461 0.3704 40\r## B 0.1589 0.1481 0.1647 -0.0166 0.1755 40\r## g 1.7591 1.9083 1.9158 -0.0075 1.7666 40\r## gp 0.3218 0.3287 0.3363 -0.0076 0.3293 40\r#Compute corrected c-statistic\r(c_opt_corr \u0026lt;- 0.5 * (val[1, 5] + 1))\r## [1] 0.8260443\r#Plot calibration\rcal \u0026lt;- rms::calibrate(pen_m1, B = 200)\rplot(cal)\r## ## n=84 Mean absolute error=0.01 Mean squared error=0.00018\r## 0.9 Quantile of absolute error=0.024\r#Output pred. probs\rhead(predict(pen_m1, type =\u0026quot;fitted\u0026quot;))\r## ERR1331793 ERR1331872 ERR1331819 ERR1331794 ERR1331851 ERR1331834 ## 0.4560689 0.4689260 0.1137757 0.6098891 0.8683044 0.2314747\rWe can see here that the Brier score is only mildly increased, and the c-statistic mildly decreased with repeated resampling. The calibration curve shows that the predictions are near the ideal across the range of predicted values. All-in-all this suggests we may expect to be able to predict patients with chronic fatigue from healthy controls with reasonable accuracy in a new sample of patients drawn from a similar population using just the three top PCs.\n\nNow we will quickly show selbal as an alternaitve. From the documentation selbal is described as:\n\rselbal is an R package for selection of balances in microbiome compositional data. As described in Rivera-Pinto et al. 2018 Balances: a new perspective for microbiome analysis https://doi.org/10.1101/219386, selbal implements a forward-selection method for the identification of two groups of taxa whose relative abundance, or balance, is associated with the response variable of interest.\rIt requires much less typing…so let’s give it a go. This approach is computationally expensive (especially with larger datasets). So below we only use 1 repeat of 5-fold cross-validation to tune the selections. In practice, we would want to turn these numbers up to get better estimates. We will also aggregate the taxa to the family-level to speed up the computation.\n\r#Agglomerate taxa\r(ps_family \u0026lt;- phyloseq::tax_glom(ps, \u0026quot;Family\u0026quot;))\r## phyloseq-class experiment-level object\r## otu_table() OTU Table: [ 30 taxa and 84 samples ]\r## sample_data() Sample Data: [ 84 samples by 23 sample variables ]\r## tax_table() Taxonomy Table: [ 30 taxa by 7 taxonomic ranks ]\r## phy_tree() Phylogenetic Tree: [ 30 tips and 29 internal nodes ]\r## refseq() DNAStringSet: [ 30 reference sequences ]\rphyloseq::taxa_names(ps_family) \u0026lt;- phyloseq::tax_table(ps_family)[, \u0026quot;Family\u0026quot;]\r#Run selbal\rcv_sebal \u0026lt;- selbal::selbal.cv(x = data.frame(t(data.frame(phyloseq::otu_table(ps_family)))), y = phyloseq::sample_data(ps_family)$Status, n.fold = 5, n.iter = 1) \r## ## ## ############################################################### ## STARTING selbal.cv FUNCTION ## ###############################################################\r## ## #-------------------------------------------------------------# ## # ZERO REPLACEMENT . . .\r## Loading required package: MASS\r## ## Attaching package: \u0026#39;MASS\u0026#39;\r## The following object is masked from \u0026#39;package:dplyr\u0026#39;:\r## ## select\r## Loading required package: NADA\r## ## Attaching package: \u0026#39;NADA\u0026#39;\r## The following object is masked from \u0026#39;package:IRanges\u0026#39;:\r## ## cor\r## The following object is masked from \u0026#39;package:S4Vectors\u0026#39;:\r## ## cor\r## The following object is masked from \u0026#39;package:stats\u0026#39;:\r## ## cor\r## Loading required package: truncnorm\r## Loading required package: miscF\r## Loading required package: R2jags\r## Loading required package: rjags\r## Loading required package: coda\r## Warning: package \u0026#39;coda\u0026#39; was built under R version 3.6.1\r## Linked to JAGS 4.3.0\r## Loaded modules: basemod,bugs\r## ## Attaching package: \u0026#39;R2jags\u0026#39;\r## The following object is masked from \u0026#39;package:coda\u0026#39;:\r## ## traceplot\r## ## Attaching package: \u0026#39;miscF\u0026#39;\r## The following object is masked from \u0026#39;package:Hmisc\u0026#39;:\r## ## rMultinom\r## ## , . . . FINISHED. ## #-------------------------------------------------------------#\r## ## #-------------------------------------------------------------# ## # Starting the cross - validation procedure . . .\r## Warning in e$fun(obj, substitute(ex), parent.frame(), e$data): already\r## exporting variable(s): logit.acc\r## ## . . . finished. ## #-------------------------------------------------------------# ## ###############################################################\r## ## The optimal number of variables is: 2\r## Setting levels: control = Control, case = Chronic Fatigue\r## Setting direction: controls \u0026lt; cases\r## Setting levels: control = Control, case = Chronic Fatigue\r## Setting direction: controls \u0026lt; cases\r## ## Attaching package: \u0026#39;gridExtra\u0026#39;\r## The following object is masked from \u0026#39;package:Biobase\u0026#39;:\r## ## combine\r## The following object is masked from \u0026#39;package:BiocGenerics\u0026#39;:\r## ## combine\r## The following object is masked from \u0026#39;package:dplyr\u0026#39;:\r## ## combine\r## ## ## ############################################################### ## . . . FINISHED. ## ###############################################################\r#plot/print results\rcv_sebal$accuracy.nvar\rplot.new()\rgrid.draw(cv_sebal$global.plot)\rHere we can see that the cross-validation selected the two balance object as having “among” the best rank-discrimination. It selected the balance with erysipelotrichaceae in the numerator and bifidobacteriaceae in the denominator. So a higher relative abundance of erysipelotrichaceae to bifidobacteriaceae was among the most informative balances. The AUC was 0.77, but as low as AUC = 0.68 with 1 repeat of 5 fold cross-validation.\nGive the model a try on the full ps object on your own. It should run in ~5 min on a standard laptop. How does the performance compare? Would you expect these results to be as reproducible as the GLM we fit? Why?\n\n\rThat concludes this session.\r\r","date":1564272000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564367153,"objectID":"f32f90b3d5b1c22d5d3b09572c0ed2f6","permalink":"/post/introduction-to-the-statistical-analysis-of-microbiome-data-in-r/","publishdate":"2019-07-28T00:00:00Z","relpermalink":"/post/introduction-to-the-statistical-analysis-of-microbiome-data-in-r/","section":"post","summary":"This post is also from the Introduction to Metagenomics Summer Workshop and provides a quick introduction to some common analytic methods used to analyze microbiome data. I thought it might be of interest to a broader audience so decided to post it here.\n\nThe goal of this session is to provide you with a high-level introduction to some common analytic methods used to analyze microbiome data. It will also serve to introduce you several popular R packages developed specifically for microbiome data analysis.","tags":["Microbiome","R","Data Analysis"],"title":"Introduction to the Statistical Analysis of Microbiome Data in R","type":"post"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view \r Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"}]